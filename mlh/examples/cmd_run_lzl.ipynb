{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "temp = 0.1\n",
    "training_type = 'TrainTargetLogitNorm'\n",
    "clear =f'>./{training_type}_mia_{temp}temp.log'\n",
    "\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "\n",
    "#cmd = f'nohup python train_target_models.py --mode target --training_type {training_type} --temp {temp}'\n",
    "#os.system(cmd)\n",
    "cmd = f'nohup python train_target_models.py --mode shadow --training_type {training_type}  --temp {temp}'\n",
    "#os.system(cmd)\n",
    "clear = f'>./mia_{training_type}.log'\n",
    "#os.system(clear)\n",
    "cmd = f'nohup python mia_example.py --training_type {training_type} --temp {temp} > mia_{training_type}.log 2>&1'\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup python train_target_models_noinference.py --log_path ./save0 --gpu 0 --mode target --training_type NormalLoss --loss_type flood --learning_rate 0.01 --epochs 100 --temp 1 & && nohup python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode shadow --training_type NormalLoss --loss_type flood --learning_rate 0.01 --epochs 100 --temp 1 && nohup python mia_example_only_target.py --training_type NormalLoss --loss_type flood --log_path ./save0 --temp 1 --attack_type metric-based> mia_NormalLoss_flood_metric-based.log 2>&1 &\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33, Total Sample: 15000, Train Acc: 72.940, Test Acc: 65.580, Loss: 2.550, Total Time: 275.001s\n",
      "Train Epoch: 34, Total Sample: 15000, Train Acc: 71.880, Test Acc: 64.840, Loss: 3.499, Total Time: 283.204s\n",
      "Train Epoch: 35, Total Sample: 15000, Train Acc: 75.760, Test Acc: 67.613, Loss: 0.497, Total Time: 291.400s\n",
      "Train Epoch: 36, Total Sample: 15000, Train Acc: 76.867, Test Acc: 68.600, Loss: 2.277, Total Time: 299.575s\n",
      "Train Epoch: 37, Total Sample: 15000, Train Acc: 78.927, Test Acc: 70.200, Loss: 2.121, Total Time: 307.735s\n",
      "Train Epoch: 38, Total Sample: 15000, Train Acc: 75.967, Test Acc: 68.487, Loss: 3.309, Total Time: 315.926s\n",
      "Train Epoch: 39, Total Sample: 15000, Train Acc: 75.653, Test Acc: 67.707, Loss: 2.562, Total Time: 324.100s\n",
      "Train Epoch: 40, Total Sample: 15000, Train Acc: 77.953, Test Acc: 69.887, Loss: 1.779, Total Time: 332.324s\n",
      "Train Epoch: 41, Total Sample: 15000, Train Acc: 78.127, Test Acc: 69.373, Loss: 2.766, Total Time: 340.539s\n",
      "Train Epoch: 42, Total Sample: 15000, Train Acc: 78.700, Test Acc: 69.453, Loss: 1.528, Total Time: 348.751s\n",
      "Train Epoch: 43, Total Sample: 15000, Train Acc: 76.660, Test Acc: 68.200, Loss: 3.636, Total Time: 356.972s\n",
      "Train Epoch: 44, Total Sample: 15000, Train Acc: 82.287, Test Acc: 71.760, Loss: 2.335, Total Time: 365.162s\n",
      "Train Epoch: 45, Total Sample: 15000, Train Acc: 73.753, Test Acc: 65.500, Loss: 0.957, Total Time: 373.394s\n",
      "Train Epoch: 46, Total Sample: 15000, Train Acc: 81.007, Test Acc: 69.740, Loss: 4.187, Total Time: 381.598s\n",
      "Train Epoch: 47, Total Sample: 15000, Train Acc: 81.360, Test Acc: 71.427, Loss: 3.500, Total Time: 389.972s\n",
      "Train Epoch: 48, Total Sample: 15000, Train Acc: 82.060, Test Acc: 70.873, Loss: 1.840, Total Time: 398.508s\n",
      "Train Epoch: 49, Total Sample: 15000, Train Acc: 83.040, Test Acc: 72.047, Loss: 3.192, Total Time: 407.068s\n",
      "Train Epoch: 50, Total Sample: 15000, Train Acc: 79.600, Test Acc: 69.833, Loss: 1.802, Total Time: 415.591s\n",
      "Train Epoch: 51, Total Sample: 15000, Train Acc: 83.387, Test Acc: 71.680, Loss: 3.769, Total Time: 424.155s\n",
      "Train Epoch: 52, Total Sample: 15000, Train Acc: 82.480, Test Acc: 71.453, Loss: 3.388, Total Time: 432.710s\n",
      "Train Epoch: 53, Total Sample: 15000, Train Acc: 84.460, Test Acc: 72.227, Loss: 2.796, Total Time: 441.188s\n",
      "Train Epoch: 54, Total Sample: 15000, Train Acc: 84.133, Test Acc: 72.700, Loss: 0.879, Total Time: 449.759s\n",
      "Train Epoch: 55, Total Sample: 15000, Train Acc: 83.573, Test Acc: 70.960, Loss: 1.267, Total Time: 458.278s\n",
      "Train Epoch: 56, Total Sample: 15000, Train Acc: 85.140, Test Acc: 72.767, Loss: 2.281, Total Time: 466.905s\n",
      "Train Epoch: 57, Total Sample: 15000, Train Acc: 85.587, Test Acc: 73.013, Loss: 3.065, Total Time: 475.133s\n",
      "Train Epoch: 58, Total Sample: 15000, Train Acc: 86.047, Test Acc: 73.047, Loss: 2.783, Total Time: 483.336s\n",
      "Train Epoch: 59, Total Sample: 15000, Train Acc: 86.553, Test Acc: 73.087, Loss: 2.315, Total Time: 491.570s\n",
      "Train Epoch: 60, Total Sample: 15000, Train Acc: 86.907, Test Acc: 73.173, Loss: 4.398, Total Time: 499.827s\n",
      "Train Epoch: 61, Total Sample: 15000, Train Acc: 84.780, Test Acc: 72.233, Loss: 2.928, Total Time: 508.008s\n",
      "Train Epoch: 62, Total Sample: 15000, Train Acc: 87.733, Test Acc: 73.107, Loss: 1.143, Total Time: 516.176s\n",
      "Train Epoch: 63, Total Sample: 15000, Train Acc: 88.533, Test Acc: 73.840, Loss: 3.749, Total Time: 524.348s\n",
      "Train Epoch: 64, Total Sample: 15000, Train Acc: 88.167, Test Acc: 73.080, Loss: 1.581, Total Time: 532.496s\n",
      "Train Epoch: 65, Total Sample: 15000, Train Acc: 87.733, Test Acc: 73.420, Loss: 1.953, Total Time: 540.689s\n",
      "Train Epoch: 66, Total Sample: 15000, Train Acc: 88.913, Test Acc: 73.927, Loss: 3.263, Total Time: 548.873s\n",
      "Train Epoch: 67, Total Sample: 15000, Train Acc: 86.527, Test Acc: 72.327, Loss: 1.481, Total Time: 557.042s\n"
     ]
    }
   ],
   "source": [
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_target_models.py --mode target --training_type NormalLoss --loss_type focal --learning_rate 0.002\n",
      "nohup python train_target_models.py --mode shadow --training_type NormalLoss --loss_type focal --learning_rate 0.002\n",
      "nohup python mia_example.py --training_type NormalLoss --loss_type focal > mia_NormalLoss_focal.log 2>&1 &\n",
      "nohup python train_target_models.py --mode shadow --training_type NormalLoss --loss_type focal --learning_rate 0.002 && nohup python mia_example.py --training_type NormalLoss --loss_type focal > mia_NormalLoss_focal.log 2>&1 &\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "temp = 0.1\n",
    "training_type = 'NormalLoss'\n",
    "clear =f'>./{training_type}_mia_{temp}temp.log'\n",
    "loss_type = 'focal'\n",
    "learning_rate = 0.002\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal\n",
    "cmd1 = f'python train_target_models.py --mode target --training_type {training_type} --loss_type {loss_type} --learning_rate {learning_rate}' \n",
    "cmd2 = f'nohup python train_target_models.py --mode shadow --training_type {training_type} --loss_type {loss_type} --learning_rate {learning_rate}'\n",
    "cmd3 = f'nohup python mia_example.py --training_type {training_type} --loss_type {loss_type}  > mia_{training_type}_{loss_type}.log 2>&1 &'\n",
    "print(cmd1)\n",
    "print(cmd2)\n",
    "print(cmd3)\n",
    "print(f'{cmd2} && {cmd3}')\n",
    "\n",
    "cmd =f'nohup {cmd1} && {cmd2} && {cmd3}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list =['ce', 'focal', 'mae', 'gce', 'sce', 'ldam', 'logit_norm', 'normreg', 'logneg', 'logit_clip', 'cnorm', 'tlnorm', 'nlnl', 'nce', 'ael', 'aul', 'phuber', 'taylor', 'cores', 'ncemae', 'ngcemae', 'ncerce', 'nceagce', 'flood', 'logit_cliping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_dist ={'learning_rate' : 0.005, 'epochs' : 200 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focal_dist['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_target_models.py --gpu 1 --mode target --training_type NormalLoss --loss_type logit_norm --learning_rate 0.01 --epochs 100 --temp 0.04\n",
      "nohup python train_target_models.py --gpu 1 --mode shadow --training_type NormalLoss --loss_type logit_norm --learning_rate 0.01 --epochs 100 --temp 0.04\n",
      "nohup python mia_example.py --training_type NormalLoss --loss_type logit_norm --temp 0.04 --attack_type metric-based> mia_NormalLoss_logit_norm.log 2>&1 &\n",
      "nohup python train_target_models.py --gpu 1 --mode shadow --training_type NormalLoss --loss_type logit_norm --learning_rate 0.01 --epochs 100 --temp 0.04 && nohup python mia_example.py --training_type NormalLoss --loss_type logit_norm --temp 0.04 --attack_type metric-based> mia_NormalLoss_logit_norm.log 2>&1 &\n",
      "nohup python train_target_models.py --gpu 1 --mode target --training_type NormalLoss --loss_type logit_norm --learning_rate 0.01 --epochs 100 --temp 0.04 && nohup python train_target_models.py --gpu 1 --mode shadow --training_type NormalLoss --loss_type logit_norm --learning_rate 0.01 --epochs 100 --temp 0.04 && nohup python mia_example.py --training_type NormalLoss --loss_type logit_norm --temp 0.04 --attack_type metric-based> mia_NormalLoss_logit_norm.log 2>&1 &\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gup = 1\n",
    "temp = 0.04\n",
    "training_type = 'NormalLoss'\n",
    "loss_type = 'logit_norm'\n",
    "attack_type = 'metric-based'\n",
    "learning_rate = 0.01\n",
    "epochs =100\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal\n",
    "cmd1 = f\"python train_target_models.py --gpu {gup} --mode target --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}\"\n",
    "cmd2 = f'nohup python train_target_models.py --gpu {gup} --mode shadow --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}'\n",
    "cmd3 = f'nohup python mia_example.py --training_type {training_type} --loss_type {loss_type} \\\n",
    "--temp {temp} --attack_type {attack_type}> mia_{training_type}_{loss_type}_{attack_type}.log 2>&1 &'\n",
    "print(cmd1)\n",
    "print(cmd2)\n",
    "print(cmd3)\n",
    "print(f'{cmd2} && {cmd3}')\n",
    "\n",
    "cmd =f'nohup {cmd1} && {cmd2} && {cmd3}'\n",
    "\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode target --training_type NormalLoss --loss_type logit_cliping --learning_rate 0.01 --epochs 100 --temp 1\n",
      "nohup python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode shadow --training_type NormalLoss --loss_type logit_cliping --learning_rate 0.01 --epochs 100 --temp 1\n",
      "nohup python mia_example_only_target.py --training_type NormalLoss --loss_type logit_cliping --log_path ./save0 --temp 1 --attack_type metric-based> mia_NormalLoss_logit_cliping_metric-based.log 2>&1 &\n",
      "nohup python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode shadow --training_type NormalLoss --loss_type logit_cliping --learning_rate 0.01 --epochs 100 --temp 1 && nohup python mia_example_only_target.py --training_type NormalLoss --loss_type logit_cliping --log_path ./save0 --temp 1 --attack_type metric-based> mia_NormalLoss_logit_cliping_metric-based.log 2>&1 &\n",
      "nohup python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode target --training_type NormalLoss --loss_type logit_cliping --learning_rate 0.01 --epochs 100 --temp 1 && nohup python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode shadow --training_type NormalLoss --loss_type logit_cliping --learning_rate 0.01 --epochs 100 --temp 1 && nohup python mia_example_only_target.py --training_type NormalLoss --loss_type logit_cliping --log_path ./save0 --temp 1 --attack_type metric-based> mia_NormalLoss_logit_cliping_metric-based.log 2>&1 &\n"
     ]
    }
   ],
   "source": [
    "# 没有 infernce的\n",
    "\n",
    "import os\n",
    "#py = \"train_only_target_models.py\"\n",
    "py = \"train_target_models_noinference.py\"\n",
    "mia = \"mia_example_only_target.py\"\n",
    "gup = 1\n",
    "temp = 1\n",
    "training_type = 'NormalLoss'\n",
    "loss_type = 'logit_cliping'\n",
    "attack_type = 'metric-based'\n",
    "learning_rate = 0.01\n",
    "epochs =100\n",
    "log_path='./save0'\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal\n",
    "cmd1 = f\"python {py} --log_path {log_path} --gpu {gup} --mode target --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}\"\n",
    "cmd2 = f'nohup python {py} --log_path {log_path} --gpu {gup} --mode shadow --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}'\n",
    "cmd3 = f'nohup python {mia} --training_type {training_type} --loss_type {loss_type} --log_path {log_path} \\\n",
    "--temp {temp} --attack_type {attack_type}> mia_{training_type}_{loss_type}_{attack_type}.log 2>&1 &'\n",
    "print(cmd1)\n",
    "print(cmd2)\n",
    "print(cmd3)\n",
    "print(f'{cmd2} && {cmd3}')\n",
    "\n",
    "cmd =f'nohup {cmd1} && {cmd2} && {cmd3}'\n",
    "\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list =['focal', 'mae', 'ldam', 'logit_norm', 'normreg', 'logneg', 'logit_clip', 'cnorm', 'tlnorm', 'nlnl', 'nce', 'ael', 'aul', 'phuber', 'taylor', 'cores', 'ncemae', 'ngcemae', 'ncerce', 'nceagce', 'flood', 'logit_cliping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verifiedFiles already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verified\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verifiedFiles already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verifiedFiles already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "        return forward_call(*input, **kwargs)return forward_call(*input, **kwargs)\n",
      "\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "Traceback (most recent call last):\n",
      "    logits = self.model(img)\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    logits = self.model(img)    \n",
      "return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "    logits = self.model(img)\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "Traceback (most recent call last):\n",
      "  File \"train_target_models_noinference.py\", line 168, in <module>\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    total_evaluator.train(train_loader, test_loader)\n",
      "  File \"/home/liuzhenlong/MIA/MLHospital/mlh/defenses/membership_inference/NormalLoss.py\", line 121, in train\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    logits = self.model(img)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 285, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 268, in _forward_impl\n",
      "    x = self.conv1(x)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "RuntimeError: Unable to find a valid cuDNN algorithm to run convolution\n"
     ]
    }
   ],
   "source": [
    "\n",
    "py = \"train_target_models_noinference.py\"\n",
    "mia = \"mia_example_only_target.py\"\n",
    "gup = 1\n",
    "temp = 1\n",
    "training_type = 'NormalLoss'\n",
    "loss_type = loss\n",
    "attack_type = 'metric-based'\n",
    "learning_rate = 0.01\n",
    "epochs =100\n",
    "log_path='./save0'\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal\n",
    "cmd1 = f\"python {py} --log_path {log_path} --gpu {gup} --mode target --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}\"\n",
    "cmd2 = f'nohup python {py} --log_path {log_path} --gpu {gup} --mode shadow --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}'\n",
    "cmd3 = f'nohup python {mia} --training_type {training_type} --loss_type {loss_type} --log_path {log_path} \\\n",
    "--temp {temp} --attack_type {attack_type}> mia_{training_type}_{loss_type}_{attack_type}.log 2>&1 &'\n",
    "cmd =f'nohup {cmd1} && {cmd2} && {cmd3}'\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Train Epoch: 1, Total Sample: 15000, Train Acc: 36.487, Test Acc: 35.627, Loss: 7.801, Total Time: 10.523s\n",
      "Train Epoch: 2, Total Sample: 15000, Train Acc: 42.200, Test Acc: 41.420, Loss: 6.139, Total Time: 18.722s\n",
      "Train Epoch: 3, Total Sample: 15000, Train Acc: 39.600, Test Acc: 38.340, Loss: 6.513, Total Time: 26.889s\n",
      "Train Epoch: 4, Total Sample: 15000, Train Acc: 48.227, Test Acc: 47.327, Loss: 6.793, Total Time: 35.062s\n",
      "Train Epoch: 5, Total Sample: 15000, Train Acc: 29.373, Test Acc: 28.673, Loss: 4.926, Total Time: 43.268s\n",
      "Train Epoch: 6, Total Sample: 15000, Train Acc: 50.853, Test Acc: 49.793, Loss: 5.684, Total Time: 51.809s\n",
      "Train Epoch: 7, Total Sample: 15000, Train Acc: 49.807, Test Acc: 48.707, Loss: 4.973, Total Time: 60.087s\n",
      "Train Epoch: 8, Total Sample: 15000, Train Acc: 44.627, Test Acc: 42.887, Loss: 4.826, Total Time: 68.503s\n",
      "Train Epoch: 9, Total Sample: 15000, Train Acc: 56.967, Test Acc: 54.340, Loss: 4.339, Total Time: 76.922s\n",
      "Train Epoch: 10, Total Sample: 15000, Train Acc: 51.993, Test Acc: 49.853, Loss: 3.581, Total Time: 85.383s\n",
      "Train Epoch: 11, Total Sample: 15000, Train Acc: 57.600, Test Acc: 55.567, Loss: 4.053, Total Time: 93.796s\n",
      "Train Epoch: 12, Total Sample: 15000, Train Acc: 60.860, Test Acc: 57.953, Loss: 4.980, Total Time: 102.013s\n",
      "Train Epoch: 13, Total Sample: 15000, Train Acc: 51.053, Test Acc: 49.520, Loss: 5.033, Total Time: 110.290s\n",
      "Train Epoch: 14, Total Sample: 15000, Train Acc: 60.860, Test Acc: 57.813, Loss: 4.911, Total Time: 118.550s\n",
      "Train Epoch: 15, Total Sample: 15000, Train Acc: 51.773, Test Acc: 49.340, Loss: 6.361, Total Time: 126.806s\n",
      "Train Epoch: 16, Total Sample: 15000, Train Acc: 55.140, Test Acc: 52.367, Loss: 5.091, Total Time: 135.042s\n",
      "Train Epoch: 17, Total Sample: 15000, Train Acc: 63.453, Test Acc: 59.100, Loss: 3.246, Total Time: 143.229s\n",
      "Train Epoch: 18, Total Sample: 15000, Train Acc: 68.947, Test Acc: 63.620, Loss: 4.393, Total Time: 151.491s\n",
      "Train Epoch: 19, Total Sample: 15000, Train Acc: 66.980, Test Acc: 62.887, Loss: 5.071, Total Time: 159.729s\n",
      "Train Epoch: 20, Total Sample: 15000, Train Acc: 64.687, Test Acc: 60.540, Loss: 6.973, Total Time: 167.951s\n",
      "Train Epoch: 21, Total Sample: 15000, Train Acc: 63.187, Test Acc: 59.107, Loss: 2.889, Total Time: 176.225s\n",
      "Train Epoch: 22, Total Sample: 15000, Train Acc: 67.593, Test Acc: 63.127, Loss: 3.391, Total Time: 184.451s\n",
      "Train Epoch: 23, Total Sample: 15000, Train Acc: 67.827, Test Acc: 63.073, Loss: 5.302, Total Time: 192.659s\n",
      "Train Epoch: 24, Total Sample: 15000, Train Acc: 66.313, Test Acc: 61.720, Loss: 4.520, Total Time: 200.867s\n",
      "Train Epoch: 25, Total Sample: 15000, Train Acc: 67.147, Test Acc: 62.373, Loss: 5.070, Total Time: 209.114s\n",
      "Train Epoch: 26, Total Sample: 15000, Train Acc: 60.553, Test Acc: 57.333, Loss: 3.371, Total Time: 217.468s\n",
      "Train Epoch: 27, Total Sample: 15000, Train Acc: 66.027, Test Acc: 61.580, Loss: 1.660, Total Time: 226.004s\n",
      "Train Epoch: 28, Total Sample: 15000, Train Acc: 68.987, Test Acc: 63.273, Loss: 4.854, Total Time: 234.539s\n",
      "Train Epoch: 29, Total Sample: 15000, Train Acc: 71.453, Test Acc: 65.973, Loss: 3.267, Total Time: 243.073s\n",
      "Train Epoch: 30, Total Sample: 15000, Train Acc: 70.420, Test Acc: 64.453, Loss: 4.654, Total Time: 251.291s\n",
      "Train Epoch: 31, Total Sample: 15000, Train Acc: 72.487, Test Acc: 66.540, Loss: 3.473, Total Time: 259.496s\n",
      "Train Epoch: 32, Total Sample: 15000, Train Acc: 75.207, Test Acc: 68.180, Loss: 3.007, Total Time: 267.716s\n"
     ]
    }
   ],
   "source": [
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train_target_models_noinference.py --log_path ./save0 --gpu 0 --mode target --training_type NormalLoss --loss_type normreg --learning_rate 0.002 --epochs 100 --temp 1  2>&1 &\n",
      "python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode shadow --training_type NormalLoss --loss_type normreg --learning_rate 0.002 --epochs 100 --temp 1  2>&1 &\n",
      "python mia_example_only_target.py --training_type NormalLoss --loss_type normreg --log_path ./save0 --temp 1 --attack_type metric-based> ./mia_log/NormalLoss_normreg_metric-based.log 2>&1 &\n",
      "python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode shadow --training_type NormalLoss --loss_type normreg --learning_rate 0.002 --epochs 100 --temp 1  2>&1 & && wait\n",
      "nohup /bin/bash -c 'python train_target_models_noinference.py --log_path ./save0 --gpu 0 --mode target --training_type NormalLoss --loss_type normreg --learning_rate 0.002 --epochs 100 --temp 1  2>&1 & python train_target_models_noinference.py --log_path ./save0 --gpu 1 --mode shadow --training_type NormalLoss --loss_type normreg --learning_rate 0.002 --epochs 100 --temp 1  2>&1 & wait python mia_example_only_target.py --training_type NormalLoss --loss_type normreg --log_path ./save0 --temp 1 --attack_type metric-based> ./mia_log/NormalLoss_normreg_metric-based.log 2>&1 &' &\n"
     ]
    }
   ],
   "source": [
    "# 没有 infernce的 \n",
    "# 两块gpu跑\n",
    "import os\n",
    "\n",
    "\n",
    "#py = \"train_only_target_models.py\"\n",
    "py = \"train_target_models_noinference.py\"\n",
    "mia = \"mia_example_only_target.py\"\n",
    "gup0 = 0\n",
    "gup1 = 1\n",
    "temp = 1\n",
    "training_type = 'NormalLoss'\n",
    "loss_type = 'normreg'\n",
    "attack_type = 'metric-based'\n",
    "learning_rate = 0.002\n",
    "epochs =100\n",
    "log_path='./save0'\n",
    "\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal\n",
    "cmd1 = f\"python {py} --log_path {log_path} --gpu {gup0} --mode target --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}  2>&1 &\"\n",
    "cmd2 = f'python {py} --log_path {log_path} --gpu {gup1} --mode shadow --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}  2>&1 &'\n",
    "cmd3 = f'python {mia} --training_type {training_type} --loss_type {loss_type} --log_path {log_path} \\\n",
    "--temp {temp} --attack_type {attack_type}> ./mia_log/{training_type}_{loss_type}_{attack_type}.log 2>&1 &'\n",
    "\n",
    "\n",
    "\n",
    "print(cmd1)\n",
    "print(cmd2)\n",
    "print(cmd4)\n",
    "print(f'{cmd2} && {cmd3}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "Files already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Train Epoch: 1, Total Sample: 15000, Train Acc: 15.947, Test Acc: 14.960, Loss: 2.531, Total Time: 10.644s\n",
      "Train Epoch: 1, Total Sample: 15000, Train Acc: 16.320, Test Acc: 15.260, Loss: 2.492, Total Time: 10.655s\n",
      "Train Epoch: 2, Total Sample: 15000, Train Acc: 11.620, Test Acc: 11.887, Loss: 2.470, Total Time: 18.932s\n",
      "Train Epoch: 2, Total Sample: 15000, Train Acc: 17.487, Test Acc: 16.853, Loss: 2.511, Total Time: 19.301s\n",
      "Train Epoch: 3, Total Sample: 15000, Train Acc: 11.747, Test Acc: 12.667, Loss: 2.433, Total Time: 27.282s\n",
      "Train Epoch: 3, Total Sample: 15000, Train Acc: 14.407, Test Acc: 13.993, Loss: 2.477, Total Time: 27.962s\n",
      "Train Epoch: 4, Total Sample: 15000, Train Acc: 15.127, Test Acc: 14.140, Loss: 2.490, Total Time: 35.422s\n",
      "Train Epoch: 4, Total Sample: 15000, Train Acc: 12.267, Test Acc: 11.693, Loss: 2.446, Total Time: 36.332s\n",
      "Train Epoch: 5, Total Sample: 15000, Train Acc: 11.033, Test Acc: 11.207, Loss: 2.406, Total Time: 43.789s\n",
      "Train Epoch: 5, Total Sample: 15000, Train Acc: 12.540, Test Acc: 11.827, Loss: 2.393, Total Time: 44.663s\n",
      "Train Epoch: 6, Total Sample: 15000, Train Acc: 17.240, Test Acc: 16.500, Loss: 2.385, Total Time: 52.393s\n",
      "Train Epoch: 6, Total Sample: 15000, Train Acc: 13.173, Test Acc: 12.600, Loss: 2.389, Total Time: 52.954s\n",
      "Train Epoch: 7, Total Sample: 15000, Train Acc: 17.427, Test Acc: 16.793, Loss: 2.381, Total Time: 60.919s\n",
      "Train Epoch: 7, Total Sample: 15000, Train Acc: 15.173, Test Acc: 14.847, Loss: 2.407, Total Time: 61.255s\n",
      "Train Epoch: 8, Total Sample: 15000, Train Acc: 12.867, Test Acc: 13.153, Loss: 2.394, Total Time: 69.419s\n",
      "Train Epoch: 8, Total Sample: 15000, Train Acc: 12.707, Test Acc: 12.580, Loss: 2.405, Total Time: 69.437s\n",
      "Train Epoch: 9, Total Sample: 15000, Train Acc: 21.307, Test Acc: 20.893, Loss: 2.373, Total Time: 77.642s\n",
      "Train Epoch: 9, Total Sample: 15000, Train Acc: 19.693, Test Acc: 18.673, Loss: 2.351, Total Time: 77.956s\n",
      "Train Epoch: 10, Total Sample: 15000, Train Acc: 13.300, Test Acc: 13.547, Loss: 2.422, Total Time: 85.916s\n",
      "Train Epoch: 10, Total Sample: 15000, Train Acc: 19.027, Test Acc: 18.447, Loss: 2.357, Total Time: 86.450s\n",
      "Train Epoch: 11, Total Sample: 15000, Train Acc: 16.167, Test Acc: 16.187, Loss: 2.413, Total Time: 94.235s\n",
      "Train Epoch: 11, Total Sample: 15000, Train Acc: 19.680, Test Acc: 18.727, Loss: 2.363, Total Time: 94.773s\n",
      "Train Epoch: 12, Total Sample: 15000, Train Acc: 20.480, Test Acc: 20.320, Loss: 2.381, Total Time: 102.700s\n",
      "Train Epoch: 12, Total Sample: 15000, Train Acc: 16.013, Test Acc: 15.733, Loss: 2.368, Total Time: 103.095s\n",
      "Train Epoch: 13, Total Sample: 15000, Train Acc: 20.327, Test Acc: 19.253, Loss: 2.380, Total Time: 111.354s\n",
      "Train Epoch: 13, Total Sample: 15000, Train Acc: 11.000, Test Acc: 10.480, Loss: 2.365, Total Time: 111.425s\n",
      "Train Epoch: 14, Total Sample: 15000, Train Acc: 17.280, Test Acc: 16.940, Loss: 2.337, Total Time: 119.659s\n",
      "Train Epoch: 14, Total Sample: 15000, Train Acc: 12.260, Test Acc: 12.493, Loss: 2.343, Total Time: 119.678s\n",
      "Train Epoch: 15, Total Sample: 15000, Train Acc: 18.193, Test Acc: 17.473, Loss: 2.369, Total Time: 127.993s\n",
      "Train Epoch: 15, Total Sample: 15000, Train Acc: 20.760, Test Acc: 19.953, Loss: 2.391, Total Time: 128.001s\n",
      "Train Epoch: 16, Total Sample: 15000, Train Acc: 14.547, Test Acc: 14.253, Loss: 2.360, Total Time: 136.324s\n",
      "Train Epoch: 16, Total Sample: 15000, Train Acc: 18.333, Test Acc: 18.120, Loss: 2.414, Total Time: 136.325s\n",
      "Train Epoch: 17, Total Sample: 15000, Train Acc: 14.700, Test Acc: 14.000, Loss: 2.356, Total Time: 144.640s\n",
      "Train Epoch: 17, Total Sample: 15000, Train Acc: 15.667, Test Acc: 15.367, Loss: 2.376, Total Time: 144.668s\n",
      "Train Epoch: 18, Total Sample: 15000, Train Acc: 14.427, Test Acc: 14.033, Loss: 2.505, Total Time: 152.979s\n",
      "Train Epoch: 18, Total Sample: 15000, Train Acc: 16.967, Test Acc: 16.680, Loss: 2.340, Total Time: 152.978s\n",
      "Train Epoch: 19, Total Sample: 15000, Train Acc: 18.447, Test Acc: 18.140, Loss: 2.362, Total Time: 161.301s\n",
      "Train Epoch: 19, Total Sample: 15000, Train Acc: 10.247, Test Acc: 10.213, Loss: 2.351, Total Time: 161.437s\n",
      "Train Epoch: 20, Total Sample: 15000, Train Acc: 12.107, Test Acc: 12.200, Loss: 2.340, Total Time: 169.631s\n",
      "Train Epoch: 20, Total Sample: 15000, Train Acc: 15.980, Test Acc: 15.520, Loss: 2.337, Total Time: 170.088s\n",
      "Train Epoch: 21, Total Sample: 15000, Train Acc: 21.093, Test Acc: 20.373, Loss: 2.348, Total Time: 177.912s\n",
      "Train Epoch: 21, Total Sample: 15000, Train Acc: 16.920, Test Acc: 16.280, Loss: 2.397, Total Time: 178.490s\n",
      "Train Epoch: 22, Total Sample: 15000, Train Acc: 22.087, Test Acc: 21.213, Loss: 2.340, Total Time: 186.395s\n",
      "Train Epoch: 22, Total Sample: 15000, Train Acc: 15.067, Test Acc: 14.393, Loss: 2.414, Total Time: 186.813s\n",
      "Train Epoch: 23, Total Sample: 15000, Train Acc: 19.100, Test Acc: 18.980, Loss: 2.353, Total Time: 194.626s\n",
      "Train Epoch: 23, Total Sample: 15000, Train Acc: 13.153, Test Acc: 13.560, Loss: 2.397, Total Time: 195.126s\n",
      "Train Epoch: 24, Total Sample: 15000, Train Acc: 10.527, Test Acc: 10.600, Loss: 2.351, Total Time: 202.923s\n",
      "Train Epoch: 24, Total Sample: 15000, Train Acc: 12.460, Test Acc: 12.293, Loss: 2.346, Total Time: 203.710s\n",
      "Train Epoch: 25, Total Sample: 15000, Train Acc: 12.913, Test Acc: 13.127, Loss: 2.357, Total Time: 211.182s\n",
      "Train Epoch: 25, Total Sample: 15000, Train Acc: 15.973, Test Acc: 16.100, Loss: 2.375, Total Time: 211.989s\n",
      "Train Epoch: 26, Total Sample: 15000, Train Acc: 10.707, Test Acc: 10.640, Loss: 2.391, Total Time: 219.481s\n",
      "Train Epoch: 26, Total Sample: 15000, Train Acc: 16.307, Test Acc: 16.153, Loss: 2.356, Total Time: 220.256s\n",
      "Train Epoch: 27, Total Sample: 15000, Train Acc: 13.880, Test Acc: 14.020, Loss: 2.355, Total Time: 227.720s\n",
      "Train Epoch: 27, Total Sample: 15000, Train Acc: 15.827, Test Acc: 15.827, Loss: 2.333, Total Time: 228.542s\n",
      "Train Epoch: 28, Total Sample: 15000, Train Acc: 14.847, Test Acc: 13.747, Loss: 2.358, Total Time: 235.998s\n",
      "Train Epoch: 28, Total Sample: 15000, Train Acc: 18.180, Test Acc: 18.007, Loss: 2.430, Total Time: 236.802s\n",
      "Train Epoch: 29, Total Sample: 15000, Train Acc: 15.020, Test Acc: 14.933, Loss: 2.375, Total Time: 244.290s\n",
      "Train Epoch: 29, Total Sample: 15000, Train Acc: 10.447, Test Acc: 10.320, Loss: 2.403, Total Time: 245.073s\n",
      "Train Epoch: 30, Total Sample: 15000, Train Acc: 15.173, Test Acc: 14.453, Loss: 2.346, Total Time: 252.611s\n",
      "Train Epoch: 30, Total Sample: 15000, Train Acc: 19.553, Test Acc: 18.840, Loss: 2.338, Total Time: 253.649s\n",
      "Train Epoch: 31, Total Sample: 15000, Train Acc: 14.820, Test Acc: 15.853, Loss: 2.372, Total Time: 260.952s\n",
      "Train Epoch: 31, Total Sample: 15000, Train Acc: 12.913, Test Acc: 12.713, Loss: 2.436, Total Time: 261.935s\n",
      "Train Epoch: 32, Total Sample: 15000, Train Acc: 9.747, Test Acc: 10.247, Loss: 2.377, Total Time: 269.265s\n",
      "Train Epoch: 32, Total Sample: 15000, Train Acc: 15.727, Test Acc: 15.720, Loss: 2.388, Total Time: 270.251s\n",
      "Train Epoch: 33, Total Sample: 15000, Train Acc: 11.833, Test Acc: 12.480, Loss: 2.356, Total Time: 277.617s\n",
      "Train Epoch: 33, Total Sample: 15000, Train Acc: 17.513, Test Acc: 17.713, Loss: 2.338, Total Time: 278.526s\n",
      "Train Epoch: 34, Total Sample: 15000, Train Acc: 13.167, Test Acc: 13.007, Loss: 2.352, Total Time: 285.934s\n",
      "Train Epoch: 34, Total Sample: 15000, Train Acc: 13.027, Test Acc: 12.353, Loss: 2.361, Total Time: 286.792s\n",
      "Train Epoch: 35, Total Sample: 15000, Train Acc: 16.793, Test Acc: 16.140, Loss: 2.330, Total Time: 294.273s\n",
      "Train Epoch: 35, Total Sample: 15000, Train Acc: 17.220, Test Acc: 16.260, Loss: 2.374, Total Time: 295.065s\n",
      "Train Epoch: 36, Total Sample: 15000, Train Acc: 17.247, Test Acc: 16.760, Loss: 2.344, Total Time: 302.584s\n",
      "Train Epoch: 36, Total Sample: 15000, Train Acc: 14.347, Test Acc: 13.933, Loss: 2.383, Total Time: 303.327s\n",
      "Train Epoch: 37, Total Sample: 15000, Train Acc: 14.933, Test Acc: 15.527, Loss: 2.325, Total Time: 310.962s\n",
      "Train Epoch: 37, Total Sample: 15000, Train Acc: 14.300, Test Acc: 13.373, Loss: 2.359, Total Time: 311.784s\n",
      "Train Epoch: 38, Total Sample: 15000, Train Acc: 15.393, Test Acc: 14.767, Loss: 2.366, Total Time: 319.302s\n",
      "Train Epoch: 38, Total Sample: 15000, Train Acc: 11.087, Test Acc: 11.533, Loss: 2.370, Total Time: 319.990s\n",
      "Train Epoch: 39, Total Sample: 15000, Train Acc: 13.840, Test Acc: 13.600, Loss: 2.344, Total Time: 327.586s\n",
      "Train Epoch: 39, Total Sample: 15000, Train Acc: 10.120, Test Acc: 10.140, Loss: 2.353, Total Time: 328.283s\n",
      "Train Epoch: 40, Total Sample: 15000, Train Acc: 17.593, Test Acc: 17.740, Loss: 2.329, Total Time: 335.879s\n",
      "Train Epoch: 40, Total Sample: 15000, Train Acc: 11.793, Test Acc: 11.980, Loss: 2.322, Total Time: 336.556s\n",
      "Train Epoch: 41, Total Sample: 15000, Train Acc: 12.247, Test Acc: 12.453, Loss: 2.350, Total Time: 344.317s\n",
      "Train Epoch: 41, Total Sample: 15000, Train Acc: 12.707, Test Acc: 12.307, Loss: 2.338, Total Time: 344.792s\n",
      "Train Epoch: 42, Total Sample: 15000, Train Acc: 14.333, Test Acc: 14.340, Loss: 2.334, Total Time: 352.997s\n",
      "Train Epoch: 42, Total Sample: 15000, Train Acc: 15.413, Test Acc: 15.000, Loss: 2.322, Total Time: 353.147s\n",
      "Train Epoch: 43, Total Sample: 15000, Train Acc: 9.733, Test Acc: 10.287, Loss: 2.321, Total Time: 361.312s\n",
      "Train Epoch: 43, Total Sample: 15000, Train Acc: 11.027, Test Acc: 10.593, Loss: 2.353, Total Time: 361.476s\n",
      "Train Epoch: 44, Total Sample: 15000, Train Acc: 17.233, Test Acc: 17.000, Loss: 2.325, Total Time: 369.644s\n",
      "Train Epoch: 44, Total Sample: 15000, Train Acc: 10.247, Test Acc: 9.960, Loss: 2.344, Total Time: 369.716s\n",
      "Train Epoch: 45, Total Sample: 15000, Train Acc: 15.727, Test Acc: 15.693, Loss: 2.364, Total Time: 377.943s\n",
      "Train Epoch: 45, Total Sample: 15000, Train Acc: 19.807, Test Acc: 19.080, Loss: 2.337, Total Time: 378.284s\n",
      "Train Epoch: 46, Total Sample: 15000, Train Acc: 15.733, Test Acc: 15.740, Loss: 2.326, Total Time: 386.255s\n",
      "Train Epoch: 46, Total Sample: 15000, Train Acc: 18.073, Test Acc: 17.680, Loss: 2.351, Total Time: 386.900s\n",
      "Train Epoch: 47, Total Sample: 15000, Train Acc: 15.233, Test Acc: 14.873, Loss: 2.332, Total Time: 394.525s\n",
      "Train Epoch: 47, Total Sample: 15000, Train Acc: 13.107, Test Acc: 12.913, Loss: 2.345, Total Time: 395.573s\n",
      "Train Epoch: 48, Total Sample: 15000, Train Acc: 12.540, Test Acc: 11.973, Loss: 2.346, Total Time: 402.761s\n",
      "Train Epoch: 48, Total Sample: 15000, Train Acc: 12.700, Test Acc: 12.240, Loss: 2.347, Total Time: 404.251s\n",
      "Train Epoch: 49, Total Sample: 15000, Train Acc: 10.527, Test Acc: 10.427, Loss: 2.330, Total Time: 411.026s\n",
      "Train Epoch: 49, Total Sample: 15000, Train Acc: 18.653, Test Acc: 17.873, Loss: 2.323, Total Time: 412.912s\n",
      "Train Epoch: 50, Total Sample: 15000, Train Acc: 10.273, Test Acc: 10.807, Loss: 2.352, Total Time: 419.297s\n",
      "Train Epoch: 50, Total Sample: 15000, Train Acc: 14.287, Test Acc: 13.773, Loss: 2.340, Total Time: 421.592s\n",
      "Train Epoch: 51, Total Sample: 15000, Train Acc: 13.647, Test Acc: 13.607, Loss: 2.322, Total Time: 427.584s\n",
      "Train Epoch: 51, Total Sample: 15000, Train Acc: 10.380, Test Acc: 10.760, Loss: 2.324, Total Time: 429.867s\n",
      "Train Epoch: 52, Total Sample: 15000, Train Acc: 12.273, Test Acc: 12.573, Loss: 2.329, Total Time: 435.867s\n",
      "Train Epoch: 52, Total Sample: 15000, Train Acc: 12.447, Test Acc: 11.980, Loss: 2.319, Total Time: 438.141s\n",
      "Train Epoch: 53, Total Sample: 15000, Train Acc: 18.767, Test Acc: 18.160, Loss: 2.344, Total Time: 444.179s\n",
      "Train Epoch: 53, Total Sample: 15000, Train Acc: 15.607, Test Acc: 15.067, Loss: 2.339, Total Time: 446.432s\n",
      "Train Epoch: 54, Total Sample: 15000, Train Acc: 12.160, Test Acc: 11.473, Loss: 2.354, Total Time: 452.505s\n",
      "Train Epoch: 54, Total Sample: 15000, Train Acc: 13.267, Test Acc: 12.980, Loss: 2.320, Total Time: 454.746s\n",
      "Train Epoch: 55, Total Sample: 15000, Train Acc: 9.973, Test Acc: 10.080, Loss: 2.357, Total Time: 460.836s\n",
      "Train Epoch: 55, Total Sample: 15000, Train Acc: 12.520, Test Acc: 12.487, Loss: 2.362, Total Time: 463.023s\n",
      "Train Epoch: 56, Total Sample: 15000, Train Acc: 18.973, Test Acc: 17.920, Loss: 2.323, Total Time: 469.352s\n",
      "Train Epoch: 56, Total Sample: 15000, Train Acc: 12.473, Test Acc: 12.767, Loss: 2.344, Total Time: 471.276s\n",
      "Train Epoch: 57, Total Sample: 15000, Train Acc: 12.813, Test Acc: 12.727, Loss: 2.358, Total Time: 477.806s\n",
      "Train Epoch: 57, Total Sample: 15000, Train Acc: 15.140, Test Acc: 15.033, Loss: 2.328, Total Time: 479.597s\n",
      "Train Epoch: 58, Total Sample: 15000, Train Acc: 18.407, Test Acc: 17.820, Loss: 2.331, Total Time: 486.285s\n",
      "Train Epoch: 58, Total Sample: 15000, Train Acc: 13.720, Test Acc: 13.520, Loss: 2.320, Total Time: 487.897s\n",
      "Train Epoch: 59, Total Sample: 15000, Train Acc: 18.667, Test Acc: 17.700, Loss: 2.332, Total Time: 494.763s\n",
      "Train Epoch: 59, Total Sample: 15000, Train Acc: 14.327, Test Acc: 13.467, Loss: 2.315, Total Time: 496.249s\n",
      "Train Epoch: 60, Total Sample: 15000, Train Acc: 16.500, Test Acc: 15.733, Loss: 2.322, Total Time: 503.086s\n",
      "Train Epoch: 60, Total Sample: 15000, Train Acc: 14.487, Test Acc: 13.913, Loss: 2.337, Total Time: 504.593s\n",
      "Train Epoch: 61, Total Sample: 15000, Train Acc: 19.460, Test Acc: 19.253, Loss: 2.337, Total Time: 511.413s\n",
      "Train Epoch: 61, Total Sample: 15000, Train Acc: 15.680, Test Acc: 15.373, Loss: 2.354, Total Time: 512.912s\n",
      "Train Epoch: 62, Total Sample: 15000, Train Acc: 15.000, Test Acc: 14.733, Loss: 2.325, Total Time: 519.730s\n",
      "Train Epoch: 62, Total Sample: 15000, Train Acc: 11.193, Test Acc: 11.300, Loss: 2.325, Total Time: 521.230s\n",
      "Train Epoch: 63, Total Sample: 15000, Train Acc: 19.967, Test Acc: 19.793, Loss: 2.334, Total Time: 527.987s\n",
      "Train Epoch: 63, Total Sample: 15000, Train Acc: 15.327, Test Acc: 15.247, Loss: 2.312, Total Time: 529.809s\n",
      "Train Epoch: 64, Total Sample: 15000, Train Acc: 15.333, Test Acc: 15.613, Loss: 2.324, Total Time: 536.284s\n",
      "Train Epoch: 64, Total Sample: 15000, Train Acc: 20.180, Test Acc: 19.813, Loss: 2.323, Total Time: 538.246s\n",
      "Train Epoch: 65, Total Sample: 15000, Train Acc: 16.993, Test Acc: 17.267, Loss: 2.313, Total Time: 544.780s\n",
      "Train Epoch: 65, Total Sample: 15000, Train Acc: 14.167, Test Acc: 13.893, Loss: 2.314, Total Time: 546.567s\n",
      "Train Epoch: 66, Total Sample: 15000, Train Acc: 14.833, Test Acc: 14.307, Loss: 2.335, Total Time: 553.474s\n",
      "Train Epoch: 66, Total Sample: 15000, Train Acc: 20.440, Test Acc: 19.893, Loss: 2.309, Total Time: 554.837s\n",
      "Train Epoch: 67, Total Sample: 15000, Train Acc: 9.827, Test Acc: 10.353, Loss: 2.312, Total Time: 562.154s\n",
      "Train Epoch: 67, Total Sample: 15000, Train Acc: 11.947, Test Acc: 11.573, Loss: 2.326, Total Time: 563.059s\n",
      "Train Epoch: 68, Total Sample: 15000, Train Acc: 12.367, Test Acc: 11.407, Loss: 2.318, Total Time: 570.840s\n",
      "Train Epoch: 68, Total Sample: 15000, Train Acc: 17.880, Test Acc: 17.853, Loss: 2.342, Total Time: 571.332s\n",
      "Train Epoch: 69, Total Sample: 15000, Train Acc: 11.153, Test Acc: 11.713, Loss: 2.342, Total Time: 579.232s\n",
      "Train Epoch: 69, Total Sample: 15000, Train Acc: 12.073, Test Acc: 11.947, Loss: 2.317, Total Time: 579.626s\n",
      "Train Epoch: 70, Total Sample: 15000, Train Acc: 13.160, Test Acc: 13.413, Loss: 2.324, Total Time: 587.529s\n",
      "Train Epoch: 70, Total Sample: 15000, Train Acc: 13.893, Test Acc: 13.580, Loss: 2.312, Total Time: 587.914s\n",
      "Train Epoch: 71, Total Sample: 15000, Train Acc: 12.813, Test Acc: 11.987, Loss: 2.314, Total Time: 595.858s\n",
      "Train Epoch: 71, Total Sample: 15000, Train Acc: 10.340, Test Acc: 10.200, Loss: 2.355, Total Time: 596.598s\n",
      "Train Epoch: 72, Total Sample: 15000, Train Acc: 20.640, Test Acc: 20.600, Loss: 2.313, Total Time: 604.161s\n",
      "Train Epoch: 72, Total Sample: 15000, Train Acc: 12.133, Test Acc: 11.720, Loss: 2.313, Total Time: 605.263s\n",
      "Train Epoch: 73, Total Sample: 15000, Train Acc: 16.433, Test Acc: 15.333, Loss: 2.313, Total Time: 612.481s\n",
      "Train Epoch: 73, Total Sample: 15000, Train Acc: 21.687, Test Acc: 21.793, Loss: 2.316, Total Time: 613.528s\n",
      "Train Epoch: 74, Total Sample: 15000, Train Acc: 20.647, Test Acc: 20.567, Loss: 2.322, Total Time: 620.796s\n",
      "Train Epoch: 74, Total Sample: 15000, Train Acc: 17.947, Test Acc: 17.547, Loss: 2.311, Total Time: 621.787s\n",
      "Train Epoch: 75, Total Sample: 15000, Train Acc: 13.960, Test Acc: 13.680, Loss: 2.313, Total Time: 629.226s\n",
      "Train Epoch: 75, Total Sample: 15000, Train Acc: 18.947, Test Acc: 18.407, Loss: 2.312, Total Time: 630.067s\n",
      "Train Epoch: 76, Total Sample: 15000, Train Acc: 11.760, Test Acc: 12.620, Loss: 2.306, Total Time: 637.863s\n",
      "Train Epoch: 76, Total Sample: 15000, Train Acc: 13.813, Test Acc: 13.920, Loss: 2.309, Total Time: 638.367s\n",
      "Train Epoch: 77, Total Sample: 15000, Train Acc: 15.447, Test Acc: 14.667, Loss: 2.319, Total Time: 646.156s\n",
      "Train Epoch: 77, Total Sample: 15000, Train Acc: 19.740, Test Acc: 18.240, Loss: 2.312, Total Time: 646.608s\n",
      "Train Epoch: 78, Total Sample: 15000, Train Acc: 10.933, Test Acc: 11.533, Loss: 2.307, Total Time: 654.486s\n",
      "Train Epoch: 78, Total Sample: 15000, Train Acc: 11.453, Test Acc: 11.320, Loss: 2.337, Total Time: 655.055s\n",
      "Train Epoch: 79, Total Sample: 15000, Train Acc: 12.080, Test Acc: 11.360, Loss: 2.308, Total Time: 662.790s\n",
      "Train Epoch: 79, Total Sample: 15000, Train Acc: 18.273, Test Acc: 18.500, Loss: 2.308, Total Time: 663.664s\n",
      "Train Epoch: 80, Total Sample: 15000, Train Acc: 11.573, Test Acc: 11.320, Loss: 2.313, Total Time: 671.046s\n",
      "Train Epoch: 80, Total Sample: 15000, Train Acc: 19.760, Test Acc: 18.873, Loss: 2.322, Total Time: 672.345s\n",
      "Train Epoch: 81, Total Sample: 15000, Train Acc: 12.260, Test Acc: 12.107, Loss: 2.308, Total Time: 679.334s\n",
      "Train Epoch: 81, Total Sample: 15000, Train Acc: 13.767, Test Acc: 13.773, Loss: 2.307, Total Time: 680.648s\n",
      "Train Epoch: 82, Total Sample: 15000, Train Acc: 14.493, Test Acc: 14.913, Loss: 2.306, Total Time: 687.621s\n",
      "Train Epoch: 82, Total Sample: 15000, Train Acc: 19.587, Test Acc: 18.587, Loss: 2.306, Total Time: 688.957s\n",
      "Train Epoch: 83, Total Sample: 15000, Train Acc: 20.280, Test Acc: 19.627, Loss: 2.316, Total Time: 695.921s\n",
      "Train Epoch: 83, Total Sample: 15000, Train Acc: 15.853, Test Acc: 15.520, Loss: 2.306, Total Time: 697.247s\n",
      "Train Epoch: 84, Total Sample: 15000, Train Acc: 11.873, Test Acc: 11.820, Loss: 2.314, Total Time: 704.161s\n",
      "Train Epoch: 84, Total Sample: 15000, Train Acc: 17.260, Test Acc: 17.987, Loss: 2.308, Total Time: 705.510s\n",
      "Train Epoch: 85, Total Sample: 15000, Train Acc: 21.820, Test Acc: 21.373, Loss: 2.305, Total Time: 712.568s\n",
      "Train Epoch: 85, Total Sample: 15000, Train Acc: 15.833, Test Acc: 15.360, Loss: 2.309, Total Time: 713.789s\n",
      "Train Epoch: 86, Total Sample: 15000, Train Acc: 13.160, Test Acc: 13.013, Loss: 2.306, Total Time: 720.933s\n",
      "Train Epoch: 86, Total Sample: 15000, Train Acc: 20.260, Test Acc: 19.647, Loss: 2.312, Total Time: 722.061s\n",
      "Train Epoch: 87, Total Sample: 15000, Train Acc: 17.073, Test Acc: 16.047, Loss: 2.320, Total Time: 729.245s\n",
      "Train Epoch: 87, Total Sample: 15000, Train Acc: 15.267, Test Acc: 15.347, Loss: 2.324, Total Time: 730.330s\n",
      "Train Epoch: 88, Total Sample: 15000, Train Acc: 16.787, Test Acc: 16.380, Loss: 2.304, Total Time: 737.547s\n",
      "Train Epoch: 88, Total Sample: 15000, Train Acc: 16.040, Test Acc: 14.733, Loss: 2.305, Total Time: 738.645s\n",
      "Train Epoch: 89, Total Sample: 15000, Train Acc: 18.127, Test Acc: 18.280, Loss: 2.320, Total Time: 745.848s\n",
      "Train Epoch: 89, Total Sample: 15000, Train Acc: 19.467, Test Acc: 18.940, Loss: 2.306, Total Time: 746.897s\n",
      "Train Epoch: 90, Total Sample: 15000, Train Acc: 13.947, Test Acc: 14.047, Loss: 2.309, Total Time: 754.249s\n",
      "Train Epoch: 90, Total Sample: 15000, Train Acc: 15.867, Test Acc: 15.713, Loss: 2.312, Total Time: 755.195s\n",
      "Train Epoch: 91, Total Sample: 15000, Train Acc: 10.933, Test Acc: 11.140, Loss: 2.304, Total Time: 762.575s\n",
      "Train Epoch: 91, Total Sample: 15000, Train Acc: 18.627, Test Acc: 18.440, Loss: 2.311, Total Time: 763.487s\n",
      "Train Epoch: 92, Total Sample: 15000, Train Acc: 17.167, Test Acc: 17.067, Loss: 2.305, Total Time: 770.929s\n",
      "Train Epoch: 92, Total Sample: 15000, Train Acc: 20.447, Test Acc: 18.773, Loss: 2.305, Total Time: 771.765s\n",
      "Train Epoch: 93, Total Sample: 15000, Train Acc: 16.347, Test Acc: 16.620, Loss: 2.306, Total Time: 779.200s\n",
      "Train Epoch: 93, Total Sample: 15000, Train Acc: 21.700, Test Acc: 21.220, Loss: 2.304, Total Time: 780.024s\n",
      "Train Epoch: 94, Total Sample: 15000, Train Acc: 19.133, Test Acc: 17.773, Loss: 2.309, Total Time: 787.571s\n",
      "Train Epoch: 94, Total Sample: 15000, Train Acc: 18.207, Test Acc: 17.627, Loss: 2.305, Total Time: 788.333s\n",
      "Train Epoch: 95, Total Sample: 15000, Train Acc: 21.067, Test Acc: 21.347, Loss: 2.305, Total Time: 795.987s\n",
      "Train Epoch: 95, Total Sample: 15000, Train Acc: 21.693, Test Acc: 21.273, Loss: 2.304, Total Time: 796.610s\n",
      "Train Epoch: 96, Total Sample: 15000, Train Acc: 20.180, Test Acc: 19.940, Loss: 2.307, Total Time: 804.316s\n",
      "Train Epoch: 96, Total Sample: 15000, Train Acc: 22.440, Test Acc: 22.067, Loss: 2.307, Total Time: 804.967s\n",
      "Train Epoch: 97, Total Sample: 15000, Train Acc: 17.413, Test Acc: 17.733, Loss: 2.306, Total Time: 812.722s\n",
      "Train Epoch: 97, Total Sample: 15000, Train Acc: 23.480, Test Acc: 22.800, Loss: 2.304, Total Time: 813.709s\n",
      "Train Epoch: 98, Total Sample: 15000, Train Acc: 22.607, Test Acc: 21.173, Loss: 2.304, Total Time: 821.014s\n",
      "Train Epoch: 98, Total Sample: 15000, Train Acc: 22.980, Test Acc: 22.160, Loss: 2.303, Total Time: 822.295s\n",
      "Train Epoch: 99, Total Sample: 15000, Train Acc: 23.600, Test Acc: 21.840, Loss: 2.307, Total Time: 829.316s\n",
      "Train Epoch: 99, Total Sample: 15000, Train Acc: 23.660, Test Acc: 22.300, Loss: 2.304, Total Time: 830.893s\n",
      "Train Epoch: 100, Total Sample: 15000, Train Acc: 23.380, Test Acc: 22.280, Loss: 2.304, Total Time: 837.793s\n",
      "Finish Training\n",
      "Train Epoch: 100, Total Sample: 15000, Train Acc: 22.427, Test Acc: 21.273, Loss: 2.315, Total Time: 839.160s\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "os.system(full_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup python train_target_models_noinference.py --log_path ./save_temp --gpu 0 --mode target --training_type NormalLoss --loss_type gce --learning_rate 0.01 --epochs 100 --temp 0.2  2>&1 &\n",
      "nohup python train_target_models_noinference.py --log_path ./save_temp --gpu 1 --mode shadow --training_type NormalLoss --loss_type gce --learning_rate 0.01 --epochs 100 --temp 0.2  2>&1 &\n",
      "nohup python train_target_models_noinference.py --log_path ./save_temp --gpu 0 --mode target --training_type NormalLoss --loss_type gce --learning_rate 0.01 --epochs 100 --temp 0.2  2>&1 & && nohup python train_target_models_noinference.py --log_path ./save_temp --gpu 1 --mode shadow --training_type NormalLoss --loss_type gce --learning_rate 0.01 --epochs 100 --temp 0.2  2>&1 &\n"
     ]
    }
   ],
   "source": [
    "# 没有 infernce的 \n",
    "# 两块gpu跑\n",
    "import os\n",
    "\n",
    "\n",
    "#py = \"train_only_target_models.py\"\n",
    "py = \"train_target_models_noinference.py\"\n",
    "mia = \"mia_example_only_target.py\"\n",
    "gup0 = 0\n",
    "gup1 = 1\n",
    "temp = 0.2\n",
    "training_type = 'NormalLoss'\n",
    "loss_type = 'gce'\n",
    "attack_type = 'metric-based'\n",
    "learning_rate = 0.01\n",
    "epochs =100\n",
    "log_path='./save_temp'\n",
    "\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal\n",
    "cmd1 = f\"nohup python {py} --log_path {log_path} --gpu {gup0} --mode target --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}  2>&1 &\"\n",
    "cmd2 = f'nohup python {py} --log_path {log_path} --gpu {gup1} --mode shadow --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}  2>&1 &'\n",
    "\n",
    "\n",
    "print(cmd1)\n",
    "print(cmd2)\n",
    "\n",
    "print(f'{cmd1} && {cmd2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "Files already downloaded and verifiedFiles already downloaded and verified\n",
      "\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 15000 \t target_test: 15000\n",
      "Train Epoch: 5, Total Sample: 15000, Train Acc: 37.960, Test Acc: 36.753, Loss: 0.894, Total Time: 44.040s\n",
      "Train Epoch: 5, Total Sample: 15000, Train Acc: 42.680, Test Acc: 41.413, Loss: 0.608, Total Time: 44.282s\n",
      "Train Epoch: 6, Total Sample: 15000, Train Acc: 55.587, Test Acc: 51.720, Loss: 0.714, Total Time: 52.531s\n",
      "Train Epoch: 6, Total Sample: 15000, Train Acc: 50.473, Test Acc: 48.193, Loss: 0.888, Total Time: 53.287s\n",
      "Train Epoch: 1, Total Sample: 15000, Train Acc: 34.107, Test Acc: 33.273, Loss: 1.330, Total Time: 10.700s\n",
      "Train Epoch: 1, Total Sample: 15000, Train Acc: 38.867, Test Acc: 37.707, Loss: 1.124, Total Time: 10.910s\n",
      "Train Epoch: 7, Total Sample: 15000, Train Acc: 48.020, Test Acc: 45.253, Loss: 0.738, Total Time: 60.993s\n",
      "Train Epoch: 7, Total Sample: 15000, Train Acc: 48.500, Test Acc: 46.607, Loss: 0.749, Total Time: 61.978s\n",
      "Train Epoch: 2, Total Sample: 15000, Train Acc: 35.740, Test Acc: 34.813, Loss: 1.022, Total Time: 18.994s\n",
      "Train Epoch: 2, Total Sample: 15000, Train Acc: 43.113, Test Acc: 41.640, Loss: 1.337, Total Time: 19.204s\n",
      "Train Epoch: 8, Total Sample: 15000, Train Acc: 52.293, Test Acc: 49.727, Loss: 0.712, Total Time: 69.469s\n",
      "Train Epoch: 8, Total Sample: 15000, Train Acc: 53.573, Test Acc: 51.593, Loss: 0.599, Total Time: 70.407s\n",
      "Train Epoch: 3, Total Sample: 15000, Train Acc: 42.400, Test Acc: 40.720, Loss: 1.061, Total Time: 27.250s\n",
      "Train Epoch: 3, Total Sample: 15000, Train Acc: 48.140, Test Acc: 45.920, Loss: 1.148, Total Time: 27.713s\n",
      "Train Epoch: 9, Total Sample: 15000, Train Acc: 56.333, Test Acc: 53.160, Loss: 0.465, Total Time: 77.953s\n",
      "Train Epoch: 9, Total Sample: 15000, Train Acc: 52.233, Test Acc: 49.600, Loss: 0.704, Total Time: 78.879s\n",
      "Train Epoch: 4, Total Sample: 15000, Train Acc: 38.327, Test Acc: 37.007, Loss: 1.150, Total Time: 35.459s\n",
      "Train Epoch: 4, Total Sample: 15000, Train Acc: 45.060, Test Acc: 43.447, Loss: 1.365, Total Time: 35.997s\n",
      "Train Epoch: 10, Total Sample: 15000, Train Acc: 45.807, Test Acc: 43.753, Loss: 0.966, Total Time: 86.358s\n",
      "Train Epoch: 10, Total Sample: 15000, Train Acc: 53.360, Test Acc: 50.667, Loss: 0.469, Total Time: 87.348s\n",
      "Train Epoch: 5, Total Sample: 15000, Train Acc: 42.120, Test Acc: 41.300, Loss: 1.036, Total Time: 43.896s\n",
      "Train Epoch: 5, Total Sample: 15000, Train Acc: 47.713, Test Acc: 45.587, Loss: 0.872, Total Time: 44.363s\n",
      "Train Epoch: 11, Total Sample: 15000, Train Acc: 58.707, Test Acc: 54.493, Loss: 0.512, Total Time: 94.923s\n",
      "Train Epoch: 11, Total Sample: 15000, Train Acc: 59.700, Test Acc: 55.787, Loss: 0.630, Total Time: 95.742s\n",
      "Train Epoch: 6, Total Sample: 15000, Train Acc: 56.373, Test Acc: 53.127, Loss: 1.017, Total Time: 52.188s\n",
      "Train Epoch: 6, Total Sample: 15000, Train Acc: 53.733, Test Acc: 49.880, Loss: 1.175, Total Time: 52.507s\n",
      "Train Epoch: 12, Total Sample: 15000, Train Acc: 57.993, Test Acc: 54.233, Loss: 0.533, Total Time: 103.363s\n",
      "Train Epoch: 12, Total Sample: 15000, Train Acc: 50.880, Test Acc: 48.747, Loss: 0.954, Total Time: 104.123s\n",
      "Train Epoch: 7, Total Sample: 15000, Train Acc: 50.207, Test Acc: 47.387, Loss: 0.887, Total Time: 60.391s\n",
      "Train Epoch: 7, Total Sample: 15000, Train Acc: 50.707, Test Acc: 47.820, Loss: 0.895, Total Time: 60.651s\n",
      "Train Epoch: 13, Total Sample: 15000, Train Acc: 57.180, Test Acc: 53.507, Loss: 0.748, Total Time: 111.894s\n",
      "Train Epoch: 13, Total Sample: 15000, Train Acc: 61.860, Test Acc: 58.067, Loss: 0.515, Total Time: 112.595s\n",
      "Train Epoch: 8, Total Sample: 15000, Train Acc: 49.520, Test Acc: 47.833, Loss: 0.846, Total Time: 68.642s\n",
      "Train Epoch: 8, Total Sample: 15000, Train Acc: 54.027, Test Acc: 51.907, Loss: 1.063, Total Time: 68.974s\n",
      "Train Epoch: 14, Total Sample: 15000, Train Acc: 56.293, Test Acc: 51.713, Loss: 0.659, Total Time: 120.379s\n",
      "Train Epoch: 14, Total Sample: 15000, Train Acc: 59.307, Test Acc: 54.727, Loss: 0.737, Total Time: 121.008s\n",
      "Train Epoch: 9, Total Sample: 15000, Train Acc: 61.453, Test Acc: 57.053, Loss: 1.002, Total Time: 76.869s\n",
      "Train Epoch: 9, Total Sample: 15000, Train Acc: 56.307, Test Acc: 52.060, Loss: 0.543, Total Time: 77.637s\n",
      "Train Epoch: 15, Total Sample: 15000, Train Acc: 56.313, Test Acc: 52.487, Loss: 0.673, Total Time: 129.059s\n",
      "Train Epoch: 15, Total Sample: 15000, Train Acc: 59.413, Test Acc: 55.080, Loss: 0.719, Total Time: 129.666s\n",
      "Train Epoch: 10, Total Sample: 15000, Train Acc: 61.727, Test Acc: 57.553, Loss: 0.776, Total Time: 85.194s\n",
      "Train Epoch: 10, Total Sample: 15000, Train Acc: 59.233, Test Acc: 55.420, Loss: 1.124, Total Time: 86.131s\n",
      "Train Epoch: 16, Total Sample: 15000, Train Acc: 65.953, Test Acc: 59.547, Loss: 0.700, Total Time: 137.409s\n",
      "Train Epoch: 16, Total Sample: 15000, Train Acc: 57.447, Test Acc: 53.373, Loss: 0.710, Total Time: 138.161s\n",
      "Train Epoch: 11, Total Sample: 15000, Train Acc: 60.213, Test Acc: 56.293, Loss: 0.823, Total Time: 93.539s\n",
      "Train Epoch: 11, Total Sample: 15000, Train Acc: 50.320, Test Acc: 45.927, Loss: 0.548, Total Time: 94.432s\n",
      "Train Epoch: 17, Total Sample: 15000, Train Acc: 56.233, Test Acc: 51.680, Loss: 0.707, Total Time: 145.763s\n",
      "Train Epoch: 17, Total Sample: 15000, Train Acc: 61.393, Test Acc: 57.013, Loss: 0.450, Total Time: 146.253s\n",
      "Train Epoch: 12, Total Sample: 15000, Train Acc: 49.647, Test Acc: 46.487, Loss: 0.967, Total Time: 101.512s\n",
      "Train Epoch: 12, Total Sample: 15000, Train Acc: 58.707, Test Acc: 54.473, Loss: 0.770, Total Time: 102.754s\n",
      "Train Epoch: 18, Total Sample: 15000, Train Acc: 61.413, Test Acc: 55.780, Loss: 0.500, Total Time: 154.385s\n",
      "Train Epoch: 18, Total Sample: 15000, Train Acc: 54.620, Test Acc: 51.387, Loss: 0.452, Total Time: 154.632s\n",
      "Train Epoch: 13, Total Sample: 15000, Train Acc: 67.933, Test Acc: 61.793, Loss: 0.748, Total Time: 109.846s\n",
      "Train Epoch: 13, Total Sample: 15000, Train Acc: 43.880, Test Acc: 41.060, Loss: 0.795, Total Time: 111.123s\n",
      "Train Epoch: 19, Total Sample: 15000, Train Acc: 62.153, Test Acc: 57.220, Loss: 0.691, Total Time: 162.813s\n",
      "Train Epoch: 19, Total Sample: 15000, Train Acc: 64.333, Test Acc: 59.860, Loss: 0.857, Total Time: 162.892s\n",
      "Train Epoch: 14, Total Sample: 15000, Train Acc: 65.260, Test Acc: 59.840, Loss: 1.174, Total Time: 118.086s\n",
      "Train Epoch: 14, Total Sample: 15000, Train Acc: 66.093, Test Acc: 60.573, Loss: 0.918, Total Time: 119.424s\n",
      "Train Epoch: 20, Total Sample: 15000, Train Acc: 58.507, Test Acc: 52.933, Loss: 0.656, Total Time: 171.303s\n",
      "Train Epoch: 20, Total Sample: 15000, Train Acc: 54.947, Test Acc: 51.307, Loss: 0.686, Total Time: 171.313s\n",
      "Train Epoch: 15, Total Sample: 15000, Train Acc: 62.300, Test Acc: 57.733, Loss: 1.187, Total Time: 126.371s\n",
      "Train Epoch: 15, Total Sample: 15000, Train Acc: 56.820, Test Acc: 52.800, Loss: 0.743, Total Time: 127.736s\n",
      "Train Epoch: 16, Total Sample: 15000, Train Acc: 60.627, Test Acc: 55.993, Loss: 0.819, Total Time: 134.555s\n",
      "Train Epoch: 21, Total Sample: 15000, Train Acc: 61.227, Test Acc: 56.300, Loss: 0.369, Total Time: 179.781s\n",
      "Train Epoch: 21, Total Sample: 15000, Train Acc: 64.020, Test Acc: 58.500, Loss: 0.329, Total Time: 179.924s\n",
      "Train Epoch: 16, Total Sample: 15000, Train Acc: 65.587, Test Acc: 59.480, Loss: 1.005, Total Time: 136.072s\n",
      "Train Epoch: 17, Total Sample: 15000, Train Acc: 69.480, Test Acc: 62.687, Loss: 0.583, Total Time: 142.831s\n",
      "Train Epoch: 22, Total Sample: 15000, Train Acc: 66.893, Test Acc: 60.833, Loss: 0.364, Total Time: 188.252s\n",
      "Train Epoch: 22, Total Sample: 15000, Train Acc: 62.673, Test Acc: 56.987, Loss: 0.712, Total Time: 188.414s\n",
      "Train Epoch: 17, Total Sample: 15000, Train Acc: 59.827, Test Acc: 55.300, Loss: 0.759, Total Time: 144.413s\n",
      "Train Epoch: 18, Total Sample: 15000, Train Acc: 62.820, Test Acc: 57.740, Loss: 0.838, Total Time: 151.268s\n",
      "Train Epoch: 23, Total Sample: 15000, Train Acc: 65.107, Test Acc: 59.080, Loss: 0.562, Total Time: 196.709s\n",
      "Train Epoch: 23, Total Sample: 15000, Train Acc: 69.580, Test Acc: 61.853, Loss: 0.382, Total Time: 196.817s\n",
      "Train Epoch: 18, Total Sample: 15000, Train Acc: 70.387, Test Acc: 62.620, Loss: 0.489, Total Time: 152.746s\n",
      "Train Epoch: 19, Total Sample: 15000, Train Acc: 72.953, Test Acc: 65.427, Loss: 1.097, Total Time: 159.763s\n",
      "Train Epoch: 24, Total Sample: 15000, Train Acc: 68.533, Test Acc: 61.647, Loss: 0.623, Total Time: 205.184s\n",
      "Train Epoch: 24, Total Sample: 15000, Train Acc: 67.767, Test Acc: 60.300, Loss: 0.524, Total Time: 205.389s\n",
      "Train Epoch: 19, Total Sample: 15000, Train Acc: 58.593, Test Acc: 54.293, Loss: 0.857, Total Time: 161.233s\n",
      "Train Epoch: 20, Total Sample: 15000, Train Acc: 62.567, Test Acc: 57.313, Loss: 0.588, Total Time: 167.880s\n",
      "Train Epoch: 25, Total Sample: 15000, Train Acc: 70.833, Test Acc: 62.033, Loss: 0.552, Total Time: 213.639s\n",
      "Train Epoch: 25, Total Sample: 15000, Train Acc: 64.800, Test Acc: 58.707, Loss: 0.615, Total Time: 213.811s\n",
      "Train Epoch: 20, Total Sample: 15000, Train Acc: 59.113, Test Acc: 53.573, Loss: 0.976, Total Time: 169.538s\n",
      "Train Epoch: 21, Total Sample: 15000, Train Acc: 62.267, Test Acc: 55.613, Loss: 0.614, Total Time: 176.100s\n",
      "Train Epoch: 26, Total Sample: 15000, Train Acc: 68.133, Test Acc: 60.907, Loss: 0.385, Total Time: 222.116s\n",
      "Train Epoch: 26, Total Sample: 15000, Train Acc: 60.887, Test Acc: 55.713, Loss: 0.459, Total Time: 222.179s\n",
      "Train Epoch: 21, Total Sample: 15000, Train Acc: 63.147, Test Acc: 56.013, Loss: 0.328, Total Time: 177.907s\n",
      "Train Epoch: 22, Total Sample: 15000, Train Acc: 57.260, Test Acc: 52.247, Loss: 0.351, Total Time: 184.276s\n",
      "Train Epoch: 27, Total Sample: 15000, Train Acc: 71.513, Test Acc: 63.453, Loss: 0.425, Total Time: 230.534s\n",
      "Train Epoch: 27, Total Sample: 15000, Train Acc: 71.400, Test Acc: 64.093, Loss: 0.265, Total Time: 230.694s\n",
      "Train Epoch: 22, Total Sample: 15000, Train Acc: 62.840, Test Acc: 56.613, Loss: 0.878, Total Time: 186.291s\n",
      "Train Epoch: 23, Total Sample: 15000, Train Acc: 65.233, Test Acc: 57.393, Loss: 0.555, Total Time: 192.498s\n",
      "Train Epoch: 28, Total Sample: 15000, Train Acc: 67.680, Test Acc: 60.533, Loss: 0.429, Total Time: 239.141s\n",
      "Train Epoch: 28, Total Sample: 15000, Train Acc: 66.920, Test Acc: 59.673, Loss: 0.486, Total Time: 239.328s\n",
      "Train Epoch: 23, Total Sample: 15000, Train Acc: 73.393, Test Acc: 64.093, Loss: 0.619, Total Time: 194.632s\n",
      "Train Epoch: 24, Total Sample: 15000, Train Acc: 68.113, Test Acc: 61.507, Loss: 0.720, Total Time: 200.713s\n",
      "Train Epoch: 29, Total Sample: 15000, Train Acc: 73.247, Test Acc: 64.387, Loss: 0.665, Total Time: 247.403s\n",
      "Train Epoch: 29, Total Sample: 15000, Train Acc: 65.867, Test Acc: 59.520, Loss: 0.622, Total Time: 247.712s\n",
      "Train Epoch: 24, Total Sample: 15000, Train Acc: 64.787, Test Acc: 57.373, Loss: 0.645, Total Time: 203.391s\n",
      "Train Epoch: 25, Total Sample: 15000, Train Acc: 75.487, Test Acc: 65.773, Loss: 1.180, Total Time: 209.047s\n",
      "Train Epoch: 30, Total Sample: 15000, Train Acc: 74.833, Test Acc: 65.013, Loss: 0.363, Total Time: 255.772s\n",
      "Train Epoch: 30, Total Sample: 15000, Train Acc: 70.607, Test Acc: 63.133, Loss: 0.590, Total Time: 256.057s\n",
      "Train Epoch: 25, Total Sample: 15000, Train Acc: 62.200, Test Acc: 56.187, Loss: 0.503, Total Time: 211.728s\n",
      "Train Epoch: 26, Total Sample: 15000, Train Acc: 73.613, Test Acc: 64.907, Loss: 0.636, Total Time: 217.289s\n",
      "Train Epoch: 31, Total Sample: 15000, Train Acc: 72.153, Test Acc: 63.473, Loss: 0.575, Total Time: 264.355s\n",
      "Train Epoch: 31, Total Sample: 15000, Train Acc: 73.467, Test Acc: 64.400, Loss: 0.638, Total Time: 264.474s\n",
      "Train Epoch: 26, Total Sample: 15000, Train Acc: 69.413, Test Acc: 60.600, Loss: 0.625, Total Time: 220.087s\n",
      "Train Epoch: 27, Total Sample: 15000, Train Acc: 71.247, Test Acc: 62.513, Loss: 0.362, Total Time: 225.570s\n",
      "Train Epoch: 32, Total Sample: 15000, Train Acc: 73.840, Test Acc: 64.187, Loss: 0.445, Total Time: 272.921s\n",
      "Train Epoch: 32, Total Sample: 15000, Train Acc: 65.680, Test Acc: 58.367, Loss: 0.312, Total Time: 272.998s\n",
      "Train Epoch: 27, Total Sample: 15000, Train Acc: 67.533, Test Acc: 59.647, Loss: 0.699, Total Time: 228.405s\n",
      "Train Epoch: 28, Total Sample: 15000, Train Acc: 74.767, Test Acc: 64.413, Loss: 0.783, Total Time: 233.756s\n",
      "Train Epoch: 33, Total Sample: 15000, Train Acc: 75.280, Test Acc: 64.767, Loss: 0.411, Total Time: 281.289s\n",
      "Train Epoch: 33, Total Sample: 15000, Train Acc: 74.293, Test Acc: 64.727, Loss: 0.461, Total Time: 281.555s\n",
      "Train Epoch: 28, Total Sample: 15000, Train Acc: 75.187, Test Acc: 64.233, Loss: 0.672, Total Time: 236.686s\n",
      "Train Epoch: 29, Total Sample: 15000, Train Acc: 77.080, Test Acc: 66.067, Loss: 0.609, Total Time: 242.266s\n",
      "Train Epoch: 34, Total Sample: 15000, Train Acc: 66.433, Test Acc: 58.660, Loss: 0.499, Total Time: 289.729s\n",
      "Train Epoch: 29, Total Sample: 15000, Train Acc: 79.400, Test Acc: 67.840, Loss: 0.870, Total Time: 244.964s\n",
      "Train Epoch: 34, Total Sample: 15000, Train Acc: 73.873, Test Acc: 64.627, Loss: 0.463, Total Time: 290.166s\n",
      "Train Epoch: 30, Total Sample: 15000, Train Acc: 70.240, Test Acc: 61.307, Loss: 0.751, Total Time: 250.480s\n",
      "Train Epoch: 35, Total Sample: 15000, Train Acc: 72.060, Test Acc: 62.447, Loss: 0.300, Total Time: 298.178s\n",
      "Train Epoch: 30, Total Sample: 15000, Train Acc: 71.440, Test Acc: 61.233, Loss: 0.565, Total Time: 253.306s\n",
      "Train Epoch: 35, Total Sample: 15000, Train Acc: 78.233, Test Acc: 67.040, Loss: 0.362, Total Time: 298.601s\n",
      "Train Epoch: 31, Total Sample: 15000, Train Acc: 79.127, Test Acc: 66.667, Loss: 0.767, Total Time: 258.878s\n",
      "Train Epoch: 36, Total Sample: 15000, Train Acc: 77.567, Test Acc: 66.460, Loss: 0.269, Total Time: 306.605s\n",
      "Train Epoch: 31, Total Sample: 15000, Train Acc: 71.533, Test Acc: 61.827, Loss: 0.600, Total Time: 261.651s\n",
      "Train Epoch: 36, Total Sample: 15000, Train Acc: 72.600, Test Acc: 62.027, Loss: 0.622, Total Time: 307.046s\n",
      "Train Epoch: 32, Total Sample: 15000, Train Acc: 79.540, Test Acc: 67.320, Loss: 0.579, Total Time: 267.175s\n",
      "Train Epoch: 37, Total Sample: 15000, Train Acc: 74.067, Test Acc: 63.280, Loss: 0.370, Total Time: 315.001s\n",
      "Train Epoch: 32, Total Sample: 15000, Train Acc: 80.167, Test Acc: 66.513, Loss: 0.758, Total Time: 269.980s\n",
      "Train Epoch: 37, Total Sample: 15000, Train Acc: 74.253, Test Acc: 64.287, Loss: 0.322, Total Time: 315.484s\n",
      "Train Epoch: 33, Total Sample: 15000, Train Acc: 75.933, Test Acc: 64.940, Loss: 0.706, Total Time: 275.547s\n",
      "Train Epoch: 33, Total Sample: 15000, Train Acc: 79.393, Test Acc: 66.260, Loss: 0.741, Total Time: 278.253s\n",
      "Train Epoch: 38, Total Sample: 15000, Train Acc: 79.067, Test Acc: 66.887, Loss: 0.512, Total Time: 323.510s\n",
      "Train Epoch: 38, Total Sample: 15000, Train Acc: 77.427, Test Acc: 66.627, Loss: 0.452, Total Time: 324.040s\n",
      "Train Epoch: 34, Total Sample: 15000, Train Acc: 76.627, Test Acc: 65.027, Loss: 0.516, Total Time: 283.956s\n",
      "Train Epoch: 34, Total Sample: 15000, Train Acc: 79.300, Test Acc: 66.293, Loss: 0.606, Total Time: 286.555s\n",
      "Train Epoch: 39, Total Sample: 15000, Train Acc: 76.360, Test Acc: 64.680, Loss: 0.434, Total Time: 331.922s\n",
      "Train Epoch: 39, Total Sample: 15000, Train Acc: 75.440, Test Acc: 64.453, Loss: 0.469, Total Time: 332.486s\n",
      "Train Epoch: 35, Total Sample: 15000, Train Acc: 80.020, Test Acc: 66.853, Loss: 0.557, Total Time: 292.263s\n",
      "Train Epoch: 35, Total Sample: 15000, Train Acc: 81.220, Test Acc: 67.267, Loss: 0.258, Total Time: 294.873s\n",
      "Train Epoch: 40, Total Sample: 15000, Train Acc: 74.673, Test Acc: 63.227, Loss: 0.323, Total Time: 340.381s\n",
      "Train Epoch: 40, Total Sample: 15000, Train Acc: 74.813, Test Acc: 64.533, Loss: 0.480, Total Time: 340.933s\n",
      "Train Epoch: 36, Total Sample: 15000, Train Acc: 77.487, Test Acc: 64.327, Loss: 0.578, Total Time: 300.579s\n",
      "Train Epoch: 36, Total Sample: 15000, Train Acc: 80.660, Test Acc: 66.667, Loss: 0.391, Total Time: 303.196s\n",
      "Train Epoch: 41, Total Sample: 15000, Train Acc: 77.920, Test Acc: 64.613, Loss: 0.359, Total Time: 348.815s\n",
      "Train Epoch: 41, Total Sample: 15000, Train Acc: 77.313, Test Acc: 65.713, Loss: 0.431, Total Time: 349.428s\n",
      "Train Epoch: 37, Total Sample: 15000, Train Acc: 77.980, Test Acc: 65.113, Loss: 0.460, Total Time: 308.824s\n",
      "Train Epoch: 37, Total Sample: 15000, Train Acc: 84.607, Test Acc: 69.080, Loss: 0.318, Total Time: 311.468s\n",
      "Train Epoch: 42, Total Sample: 15000, Train Acc: 80.420, Test Acc: 67.460, Loss: 0.407, Total Time: 357.324s\n",
      "Train Epoch: 42, Total Sample: 15000, Train Acc: 73.967, Test Acc: 63.033, Loss: 0.439, Total Time: 357.863s\n",
      "Train Epoch: 38, Total Sample: 15000, Train Acc: 79.807, Test Acc: 65.693, Loss: 0.459, Total Time: 317.379s\n",
      "Train Epoch: 38, Total Sample: 15000, Train Acc: 84.893, Test Acc: 68.387, Loss: 0.488, Total Time: 319.725s\n",
      "Train Epoch: 43, Total Sample: 15000, Train Acc: 81.207, Test Acc: 67.433, Loss: 0.359, Total Time: 365.756s\n",
      "Train Epoch: 43, Total Sample: 15000, Train Acc: 79.927, Test Acc: 67.727, Loss: 0.319, Total Time: 366.337s\n",
      "Train Epoch: 39, Total Sample: 15000, Train Acc: 82.360, Test Acc: 67.113, Loss: 0.597, Total Time: 325.691s\n",
      "Train Epoch: 39, Total Sample: 15000, Train Acc: 72.713, Test Acc: 61.047, Loss: 0.534, Total Time: 328.188s\n",
      "Train Epoch: 44, Total Sample: 15000, Train Acc: 79.133, Test Acc: 65.473, Loss: 0.533, Total Time: 374.169s\n",
      "Train Epoch: 44, Total Sample: 15000, Train Acc: 80.373, Test Acc: 67.673, Loss: 0.473, Total Time: 374.775s\n",
      "Train Epoch: 40, Total Sample: 15000, Train Acc: 83.280, Test Acc: 67.580, Loss: 0.601, Total Time: 333.981s\n",
      "Train Epoch: 40, Total Sample: 15000, Train Acc: 85.107, Test Acc: 67.760, Loss: 0.489, Total Time: 336.733s\n",
      "Train Epoch: 45, Total Sample: 15000, Train Acc: 82.040, Test Acc: 67.420, Loss: 0.247, Total Time: 382.581s\n",
      "Train Epoch: 45, Total Sample: 15000, Train Acc: 77.307, Test Acc: 65.620, Loss: 0.475, Total Time: 383.301s\n",
      "Train Epoch: 41, Total Sample: 15000, Train Acc: 85.527, Test Acc: 68.313, Loss: 0.261, Total Time: 342.325s\n",
      "Train Epoch: 41, Total Sample: 15000, Train Acc: 79.927, Test Acc: 64.527, Loss: 0.398, Total Time: 345.172s\n",
      "Train Epoch: 46, Total Sample: 15000, Train Acc: 78.673, Test Acc: 65.433, Loss: 0.545, Total Time: 391.038s\n",
      "Train Epoch: 46, Total Sample: 15000, Train Acc: 82.167, Test Acc: 68.087, Loss: 0.766, Total Time: 391.729s\n",
      "Train Epoch: 42, Total Sample: 15000, Train Acc: 82.353, Test Acc: 67.027, Loss: 0.324, Total Time: 350.601s\n",
      "Train Epoch: 42, Total Sample: 15000, Train Acc: 80.727, Test Acc: 65.153, Loss: 0.599, Total Time: 353.488s\n",
      "Train Epoch: 47, Total Sample: 15000, Train Acc: 79.613, Test Acc: 65.867, Loss: 0.746, Total Time: 399.429s\n",
      "Train Epoch: 47, Total Sample: 15000, Train Acc: 83.047, Test Acc: 68.280, Loss: 0.552, Total Time: 400.329s\n",
      "Train Epoch: 43, Total Sample: 15000, Train Acc: 84.220, Test Acc: 67.113, Loss: 0.094, Total Time: 358.910s\n",
      "Train Epoch: 43, Total Sample: 15000, Train Acc: 77.207, Test Acc: 62.267, Loss: 0.629, Total Time: 362.007s\n",
      "Train Epoch: 48, Total Sample: 15000, Train Acc: 77.600, Test Acc: 64.473, Loss: 0.329, Total Time: 407.851s\n",
      "Train Epoch: 48, Total Sample: 15000, Train Acc: 81.947, Test Acc: 68.120, Loss: 0.097, Total Time: 408.760s\n",
      "Train Epoch: 44, Total Sample: 15000, Train Acc: 84.487, Test Acc: 67.680, Loss: 0.422, Total Time: 367.232s\n",
      "Train Epoch: 44, Total Sample: 15000, Train Acc: 85.813, Test Acc: 67.820, Loss: 0.327, Total Time: 370.361s\n",
      "Train Epoch: 49, Total Sample: 15000, Train Acc: 80.393, Test Acc: 66.567, Loss: 0.363, Total Time: 416.310s\n",
      "Train Epoch: 49, Total Sample: 15000, Train Acc: 75.720, Test Acc: 63.167, Loss: 0.474, Total Time: 417.317s\n",
      "Train Epoch: 45, Total Sample: 15000, Train Acc: 83.160, Test Acc: 67.093, Loss: 0.477, Total Time: 375.658s\n",
      "Train Epoch: 45, Total Sample: 15000, Train Acc: 86.613, Test Acc: 68.253, Loss: 0.389, Total Time: 378.628s\n",
      "Train Epoch: 50, Total Sample: 15000, Train Acc: 83.140, Test Acc: 67.840, Loss: 0.225, Total Time: 424.750s\n",
      "Train Epoch: 50, Total Sample: 15000, Train Acc: 83.967, Test Acc: 69.080, Loss: 0.673, Total Time: 425.623s\n",
      "Train Epoch: 46, Total Sample: 15000, Train Acc: 82.780, Test Acc: 66.453, Loss: 0.597, Total Time: 384.070s\n",
      "Train Epoch: 46, Total Sample: 15000, Train Acc: 85.627, Test Acc: 67.173, Loss: 0.550, Total Time: 386.965s\n",
      "Train Epoch: 51, Total Sample: 15000, Train Acc: 83.073, Test Acc: 67.013, Loss: 0.449, Total Time: 433.386s\n",
      "Train Epoch: 51, Total Sample: 15000, Train Acc: 79.073, Test Acc: 66.907, Loss: 0.494, Total Time: 434.032s\n",
      "Train Epoch: 47, Total Sample: 15000, Train Acc: 82.060, Test Acc: 65.927, Loss: 0.622, Total Time: 392.546s\n",
      "Train Epoch: 47, Total Sample: 15000, Train Acc: 85.973, Test Acc: 68.327, Loss: 0.491, Total Time: 395.629s\n",
      "Train Epoch: 52, Total Sample: 15000, Train Acc: 84.587, Test Acc: 68.373, Loss: 0.337, Total Time: 441.825s\n",
      "Train Epoch: 52, Total Sample: 15000, Train Acc: 84.827, Test Acc: 69.413, Loss: 0.351, Total Time: 442.597s\n",
      "Train Epoch: 48, Total Sample: 15000, Train Acc: 89.320, Test Acc: 69.513, Loss: 0.161, Total Time: 400.835s\n",
      "Train Epoch: 48, Total Sample: 15000, Train Acc: 86.787, Test Acc: 67.987, Loss: 0.296, Total Time: 403.904s\n",
      "Train Epoch: 53, Total Sample: 15000, Train Acc: 85.527, Test Acc: 68.340, Loss: 0.268, Total Time: 450.223s\n",
      "Train Epoch: 53, Total Sample: 15000, Train Acc: 85.073, Test Acc: 68.873, Loss: 0.630, Total Time: 451.492s\n",
      "Train Epoch: 49, Total Sample: 15000, Train Acc: 88.313, Test Acc: 68.393, Loss: 0.359, Total Time: 409.390s\n",
      "Train Epoch: 49, Total Sample: 15000, Train Acc: 86.827, Test Acc: 67.747, Loss: 0.537, Total Time: 412.267s\n",
      "Train Epoch: 54, Total Sample: 15000, Train Acc: 84.607, Test Acc: 68.167, Loss: 0.282, Total Time: 458.564s\n",
      "Train Epoch: 54, Total Sample: 15000, Train Acc: 85.000, Test Acc: 68.687, Loss: 0.211, Total Time: 459.858s\n",
      "Train Epoch: 50, Total Sample: 15000, Train Acc: 88.920, Test Acc: 69.233, Loss: 0.760, Total Time: 417.714s\n",
      "Train Epoch: 50, Total Sample: 15000, Train Acc: 90.173, Test Acc: 68.927, Loss: 0.441, Total Time: 420.859s\n",
      "Train Epoch: 55, Total Sample: 15000, Train Acc: 84.527, Test Acc: 67.873, Loss: 0.097, Total Time: 467.007s\n",
      "Train Epoch: 55, Total Sample: 15000, Train Acc: 81.980, Test Acc: 66.980, Loss: 0.250, Total Time: 468.327s\n",
      "Train Epoch: 51, Total Sample: 15000, Train Acc: 88.993, Test Acc: 69.200, Loss: 0.470, Total Time: 426.091s\n",
      "Train Epoch: 51, Total Sample: 15000, Train Acc: 86.367, Test Acc: 67.000, Loss: 0.899, Total Time: 429.077s\n",
      "Train Epoch: 56, Total Sample: 15000, Train Acc: 86.060, Test Acc: 68.673, Loss: 0.223, Total Time: 475.384s\n",
      "Train Epoch: 56, Total Sample: 15000, Train Acc: 87.033, Test Acc: 69.680, Loss: 0.486, Total Time: 476.795s\n",
      "Train Epoch: 52, Total Sample: 15000, Train Acc: 90.187, Test Acc: 69.387, Loss: 0.443, Total Time: 434.660s\n",
      "Train Epoch: 52, Total Sample: 15000, Train Acc: 89.847, Test Acc: 68.907, Loss: 0.488, Total Time: 437.417s\n",
      "Train Epoch: 57, Total Sample: 15000, Train Acc: 87.460, Test Acc: 69.527, Loss: 0.477, Total Time: 483.842s\n",
      "Train Epoch: 57, Total Sample: 15000, Train Acc: 84.347, Test Acc: 68.320, Loss: 0.356, Total Time: 485.226s\n",
      "Train Epoch: 53, Total Sample: 15000, Train Acc: 90.347, Test Acc: 69.620, Loss: 0.586, Total Time: 443.118s\n",
      "Train Epoch: 53, Total Sample: 15000, Train Acc: 90.780, Test Acc: 68.993, Loss: 0.196, Total Time: 445.802s\n",
      "Train Epoch: 58, Total Sample: 15000, Train Acc: 86.267, Test Acc: 68.367, Loss: 0.503, Total Time: 492.244s\n",
      "Train Epoch: 58, Total Sample: 15000, Train Acc: 87.940, Test Acc: 69.913, Loss: 0.499, Total Time: 493.902s\n",
      "Train Epoch: 54, Total Sample: 15000, Train Acc: 88.153, Test Acc: 68.140, Loss: 0.336, Total Time: 451.439s\n",
      "Train Epoch: 54, Total Sample: 15000, Train Acc: 89.913, Test Acc: 68.593, Loss: 0.160, Total Time: 454.166s\n",
      "Train Epoch: 59, Total Sample: 15000, Train Acc: 86.293, Test Acc: 67.787, Loss: 0.271, Total Time: 500.885s\n",
      "Train Epoch: 59, Total Sample: 15000, Train Acc: 86.960, Test Acc: 69.440, Loss: 0.279, Total Time: 502.392s\n",
      "Train Epoch: 55, Total Sample: 15000, Train Acc: 88.687, Test Acc: 67.700, Loss: 0.359, Total Time: 459.722s\n",
      "Train Epoch: 55, Total Sample: 15000, Train Acc: 91.467, Test Acc: 69.647, Loss: 0.189, Total Time: 462.518s\n",
      "Train Epoch: 60, Total Sample: 15000, Train Acc: 88.460, Test Acc: 69.300, Loss: 0.741, Total Time: 509.332s\n",
      "Train Epoch: 60, Total Sample: 15000, Train Acc: 86.713, Test Acc: 69.127, Loss: 0.489, Total Time: 510.793s\n",
      "Train Epoch: 56, Total Sample: 15000, Train Acc: 91.187, Test Acc: 70.100, Loss: 0.354, Total Time: 468.156s\n",
      "Train Epoch: 56, Total Sample: 15000, Train Acc: 91.927, Test Acc: 69.247, Loss: 0.628, Total Time: 470.949s\n",
      "Train Epoch: 61, Total Sample: 15000, Train Acc: 84.620, Test Acc: 66.860, Loss: 0.431, Total Time: 517.950s\n",
      "Train Epoch: 61, Total Sample: 15000, Train Acc: 87.713, Test Acc: 69.707, Loss: 0.171, Total Time: 519.294s\n",
      "Train Epoch: 57, Total Sample: 15000, Train Acc: 91.647, Test Acc: 70.007, Loss: 0.395, Total Time: 476.661s\n",
      "Train Epoch: 57, Total Sample: 15000, Train Acc: 91.180, Test Acc: 68.947, Loss: 0.443, Total Time: 479.396s\n",
      "Train Epoch: 62, Total Sample: 15000, Train Acc: 89.207, Test Acc: 69.287, Loss: 0.258, Total Time: 526.395s\n",
      "Train Epoch: 62, Total Sample: 15000, Train Acc: 88.313, Test Acc: 70.367, Loss: 0.336, Total Time: 527.731s\n",
      "Train Epoch: 58, Total Sample: 15000, Train Acc: 86.333, Test Acc: 65.713, Loss: 0.605, Total Time: 485.140s\n",
      "Train Epoch: 58, Total Sample: 15000, Train Acc: 93.933, Test Acc: 70.513, Loss: 0.446, Total Time: 487.766s\n",
      "Train Epoch: 63, Total Sample: 15000, Train Acc: 88.873, Test Acc: 68.973, Loss: 0.450, Total Time: 534.812s\n",
      "Train Epoch: 63, Total Sample: 15000, Train Acc: 88.673, Test Acc: 69.767, Loss: 0.260, Total Time: 536.426s\n",
      "Train Epoch: 59, Total Sample: 15000, Train Acc: 93.620, Test Acc: 70.087, Loss: 0.467, Total Time: 493.296s\n",
      "Train Epoch: 59, Total Sample: 15000, Train Acc: 93.593, Test Acc: 69.860, Loss: 0.259, Total Time: 496.071s\n",
      "Train Epoch: 64, Total Sample: 15000, Train Acc: 89.693, Test Acc: 69.500, Loss: 0.257, Total Time: 543.248s\n",
      "Train Epoch: 64, Total Sample: 15000, Train Acc: 88.633, Test Acc: 70.367, Loss: 0.101, Total Time: 544.837s\n"
     ]
    }
   ],
   "source": [
    "os.system(cmd1)\n",
    "os.system(cmd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_commands(params):\n",
    "    py = params.get('py', \"train_target_models_noinference.py\")\n",
    "    log_path = params.get('log_path', './save_temp')\n",
    "    gup0 = params.get('gup0', 0)\n",
    "    gup1 = params.get('gup1', 1)\n",
    "    training_type = params.get('training_type', 'NormalLoss')\n",
    "    loss_type = params.get('loss_type', 'gce')\n",
    "    learning_rate = params.get('learning_rate', 0.01)\n",
    "    epochs = params.get('epochs', 100)\n",
    "    temp = params.get('temp', 0.2)\n",
    "\n",
    "    cmd1 = f\"nohup python {py} --log_path {log_path} --gpu {gup0} --mode target --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}  2>&1 &\"\n",
    "    \n",
    "    cmd2 = f'nohup python {py} --log_path {log_path} --gpu {gup1} --mode shadow --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp}  2>&1 &'\n",
    "    \n",
    "    return cmd1, cmd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'py': \"train_target_models_noinference.py\",\n",
    "    'log_path': './save_temp',\n",
    "    'gup0': 0,\n",
    "    'gup1': 1,\n",
    "    'training_type': 'NormalLoss',\n",
    "    'loss_type': 'gce',\n",
    "    'learning_rate': 0.01,\n",
    "    'epochs': 100,\n",
    "    'temp': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd1, cmd2 = generate_commands(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nohup python mia_example_only_target.py --training_type NormalLoss --loss_type focal --log_path ./save0 --temp 1 --attack_type metric-based> /mia_log/NormalLoss_focal_metric-based.log 2>&1 &\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup python train_only_target_models.py --log_path ./save2 --gpu 0 --mode target --training_type NormalLoss --loss_type flood --learning_rate 0.01 --epochs 100 --temp 1 2>&1 &\n"
     ]
    }
   ],
   "source": [
    "# 没有 infernce的 \n",
    "# 两块gpu跑\n",
    "from fractions import Fraction\n",
    "import os\n",
    "\n",
    "\n",
    "#py = \"train_only_target_models.py\"\n",
    "#py = \"train_target_models_noinference.py\"\n",
    "py = \"train_only_target_models.py\"\n",
    "mia = \"mia_example_only_target.py\"\n",
    "gup0 = 0\n",
    "gup1 = 1\n",
    "temp = 1\n",
    "training_type = 'NormalLoss'\n",
    "loss_type = 'flood'\n",
    "attack_type = 'metric-based'\n",
    "learning_rate = 0.01\n",
    "epochs =100\n",
    "log_path='./save2'\n",
    "divide_ratio = 50000,10000\n",
    "# 'Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE, TrainTargetLogitNorm'\n",
    "# python train_target_models.py --mode target --training_type NormalLoss  --loss_type focal\n",
    "cmd1 = f\"nohup python {py} --log_path {log_path} --gpu {gup0} --mode target --training_type {training_type} \\\n",
    "--loss_type {loss_type} --learning_rate {learning_rate} --epochs {epochs} --temp {temp} 2>&1 &\"\n",
    "\n",
    "print(cmd1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 50000  \t target_test: 10000\n",
      "Train Epoch: 1, Total Sample: 50000, Train Acc: 45.498, Test Acc: 44.930, Loss: 1.722, Total Time: 22.623s\n",
      "Train Epoch: 2, Total Sample: 50000, Train Acc: 45.352, Test Acc: 44.530, Loss: 1.112, Total Time: 43.072s\n",
      "Train Epoch: 3, Total Sample: 50000, Train Acc: 47.728, Test Acc: 47.110, Loss: 0.953, Total Time: 63.491s\n",
      "Train Epoch: 4, Total Sample: 50000, Train Acc: 61.836, Test Acc: 60.040, Loss: 1.004, Total Time: 83.938s\n",
      "Train Epoch: 5, Total Sample: 50000, Train Acc: 54.056, Test Acc: 52.000, Loss: 0.853, Total Time: 104.976s\n",
      "Train Epoch: 6, Total Sample: 50000, Train Acc: 62.450, Test Acc: 60.900, Loss: 1.038, Total Time: 125.292s\n",
      "Train Epoch: 7, Total Sample: 50000, Train Acc: 54.628, Test Acc: 52.900, Loss: 0.864, Total Time: 145.678s\n",
      "Train Epoch: 8, Total Sample: 50000, Train Acc: 69.204, Test Acc: 66.800, Loss: 0.847, Total Time: 165.989s\n",
      "Train Epoch: 9, Total Sample: 50000, Train Acc: 69.936, Test Acc: 66.910, Loss: 0.769, Total Time: 186.301s\n",
      "Train Epoch: 10, Total Sample: 50000, Train Acc: 70.406, Test Acc: 67.400, Loss: 0.648, Total Time: 206.635s\n",
      "Train Epoch: 11, Total Sample: 50000, Train Acc: 72.158, Test Acc: 69.140, Loss: 0.659, Total Time: 227.105s\n",
      "Train Epoch: 12, Total Sample: 50000, Train Acc: 68.322, Test Acc: 66.330, Loss: 0.672, Total Time: 247.548s\n",
      "Train Epoch: 13, Total Sample: 50000, Train Acc: 72.074, Test Acc: 68.290, Loss: 0.862, Total Time: 268.002s\n",
      "Train Epoch: 14, Total Sample: 50000, Train Acc: 74.656, Test Acc: 70.760, Loss: 0.571, Total Time: 288.435s\n",
      "Train Epoch: 15, Total Sample: 50000, Train Acc: 76.514, Test Acc: 72.320, Loss: 0.721, Total Time: 308.605s\n",
      "Train Epoch: 16, Total Sample: 50000, Train Acc: 78.692, Test Acc: 73.950, Loss: 0.774, Total Time: 328.826s\n",
      "Train Epoch: 17, Total Sample: 50000, Train Acc: 78.780, Test Acc: 74.560, Loss: 0.710, Total Time: 349.053s\n",
      "Train Epoch: 18, Total Sample: 50000, Train Acc: 78.396, Test Acc: 73.450, Loss: 0.486, Total Time: 369.233s\n",
      "Train Epoch: 19, Total Sample: 50000, Train Acc: 79.702, Test Acc: 74.500, Loss: 0.609, Total Time: 389.642s\n",
      "Train Epoch: 20, Total Sample: 50000, Train Acc: 73.612, Test Acc: 70.220, Loss: 0.714, Total Time: 410.220s\n",
      "Train Epoch: 21, Total Sample: 50000, Train Acc: 76.304, Test Acc: 72.010, Loss: 0.621, Total Time: 430.774s\n",
      "Train Epoch: 22, Total Sample: 50000, Train Acc: 80.502, Test Acc: 74.760, Loss: 0.665, Total Time: 451.136s\n",
      "Train Epoch: 23, Total Sample: 50000, Train Acc: 79.710, Test Acc: 74.050, Loss: 0.524, Total Time: 471.568s\n",
      "Train Epoch: 24, Total Sample: 50000, Train Acc: 82.568, Test Acc: 76.760, Loss: 0.605, Total Time: 491.887s\n",
      "Train Epoch: 25, Total Sample: 50000, Train Acc: 82.680, Test Acc: 76.760, Loss: 0.619, Total Time: 512.412s\n",
      "Train Epoch: 26, Total Sample: 50000, Train Acc: 81.494, Test Acc: 75.310, Loss: 0.581, Total Time: 533.060s\n",
      "Train Epoch: 27, Total Sample: 50000, Train Acc: 80.948, Test Acc: 75.130, Loss: 0.457, Total Time: 553.316s\n",
      "Train Epoch: 28, Total Sample: 50000, Train Acc: 83.738, Test Acc: 77.350, Loss: 0.607, Total Time: 573.705s\n",
      "Train Epoch: 29, Total Sample: 50000, Train Acc: 85.180, Test Acc: 77.990, Loss: 0.454, Total Time: 594.083s\n",
      "Train Epoch: 30, Total Sample: 50000, Train Acc: 83.956, Test Acc: 77.120, Loss: 0.381, Total Time: 614.507s\n",
      "Train Epoch: 31, Total Sample: 50000, Train Acc: 85.314, Test Acc: 78.280, Loss: 0.507, Total Time: 634.996s\n",
      "Train Epoch: 32, Total Sample: 50000, Train Acc: 85.114, Test Acc: 77.260, Loss: 0.550, Total Time: 655.493s\n",
      "Train Epoch: 33, Total Sample: 50000, Train Acc: 86.336, Test Acc: 77.770, Loss: 0.437, Total Time: 675.732s\n",
      "Train Epoch: 34, Total Sample: 50000, Train Acc: 87.406, Test Acc: 78.920, Loss: 0.344, Total Time: 696.050s\n",
      "Train Epoch: 35, Total Sample: 50000, Train Acc: 85.920, Test Acc: 77.450, Loss: 0.447, Total Time: 716.453s\n",
      "Train Epoch: 36, Total Sample: 50000, Train Acc: 87.000, Test Acc: 78.230, Loss: 0.534, Total Time: 736.795s\n",
      "Train Epoch: 37, Total Sample: 50000, Train Acc: 87.916, Test Acc: 78.930, Loss: 0.363, Total Time: 757.201s\n",
      "Train Epoch: 38, Total Sample: 50000, Train Acc: 87.782, Test Acc: 79.390, Loss: 0.485, Total Time: 777.536s\n",
      "Train Epoch: 39, Total Sample: 50000, Train Acc: 83.976, Test Acc: 76.030, Loss: 0.366, Total Time: 797.945s\n",
      "Train Epoch: 40, Total Sample: 50000, Train Acc: 88.304, Test Acc: 78.830, Loss: 0.324, Total Time: 818.372s\n",
      "Train Epoch: 41, Total Sample: 50000, Train Acc: 88.844, Test Acc: 78.600, Loss: 0.373, Total Time: 838.758s\n",
      "Train Epoch: 42, Total Sample: 50000, Train Acc: 90.044, Test Acc: 80.290, Loss: 0.531, Total Time: 859.335s\n",
      "Train Epoch: 43, Total Sample: 50000, Train Acc: 89.180, Test Acc: 78.740, Loss: 0.437, Total Time: 879.728s\n",
      "Train Epoch: 44, Total Sample: 50000, Train Acc: 88.178, Test Acc: 78.810, Loss: 0.259, Total Time: 900.015s\n",
      "Train Epoch: 45, Total Sample: 50000, Train Acc: 90.266, Test Acc: 79.210, Loss: 0.369, Total Time: 921.066s\n",
      "Train Epoch: 46, Total Sample: 50000, Train Acc: 89.230, Test Acc: 79.040, Loss: 0.535, Total Time: 941.932s\n",
      "Train Epoch: 47, Total Sample: 50000, Train Acc: 91.068, Test Acc: 79.440, Loss: 0.390, Total Time: 962.512s\n",
      "Train Epoch: 48, Total Sample: 50000, Train Acc: 90.782, Test Acc: 79.510, Loss: 0.346, Total Time: 982.889s\n",
      "Train Epoch: 49, Total Sample: 50000, Train Acc: 91.792, Test Acc: 80.590, Loss: 0.357, Total Time: 1003.123s\n",
      "Train Epoch: 50, Total Sample: 50000, Train Acc: 92.514, Test Acc: 80.410, Loss: 0.328, Total Time: 1023.411s\n",
      "Train Epoch: 51, Total Sample: 50000, Train Acc: 92.110, Test Acc: 80.370, Loss: 0.279, Total Time: 1043.754s\n",
      "Train Epoch: 52, Total Sample: 50000, Train Acc: 91.838, Test Acc: 80.030, Loss: 0.300, Total Time: 1064.158s\n",
      "Train Epoch: 53, Total Sample: 50000, Train Acc: 93.318, Test Acc: 81.210, Loss: 0.307, Total Time: 1084.573s\n",
      "Train Epoch: 54, Total Sample: 50000, Train Acc: 93.590, Test Acc: 81.030, Loss: 0.356, Total Time: 1104.928s\n",
      "Train Epoch: 55, Total Sample: 50000, Train Acc: 93.712, Test Acc: 80.750, Loss: 0.374, Total Time: 1125.310s\n",
      "Train Epoch: 56, Total Sample: 50000, Train Acc: 94.012, Test Acc: 80.680, Loss: 0.189, Total Time: 1146.227s\n",
      "Train Epoch: 57, Total Sample: 50000, Train Acc: 92.966, Test Acc: 80.220, Loss: 0.338, Total Time: 1166.564s\n",
      "Train Epoch: 58, Total Sample: 50000, Train Acc: 93.520, Test Acc: 80.320, Loss: 0.357, Total Time: 1187.030s\n",
      "Train Epoch: 59, Total Sample: 50000, Train Acc: 92.806, Test Acc: 79.680, Loss: 0.404, Total Time: 1207.251s\n",
      "Train Epoch: 60, Total Sample: 50000, Train Acc: 94.744, Test Acc: 80.390, Loss: 0.354, Total Time: 1227.380s\n",
      "Train Epoch: 61, Total Sample: 50000, Train Acc: 94.032, Test Acc: 80.620, Loss: 0.259, Total Time: 1247.585s\n",
      "Train Epoch: 62, Total Sample: 50000, Train Acc: 95.274, Test Acc: 80.900, Loss: 0.245, Total Time: 1267.883s\n",
      "Train Epoch: 63, Total Sample: 50000, Train Acc: 95.302, Test Acc: 81.660, Loss: 0.307, Total Time: 1288.167s\n",
      "Train Epoch: 64, Total Sample: 50000, Train Acc: 95.272, Test Acc: 81.460, Loss: 0.171, Total Time: 1308.378s\n",
      "Train Epoch: 65, Total Sample: 50000, Train Acc: 95.860, Test Acc: 81.680, Loss: 0.234, Total Time: 1328.618s\n",
      "Train Epoch: 66, Total Sample: 50000, Train Acc: 95.850, Test Acc: 81.140, Loss: 0.242, Total Time: 1348.844s\n",
      "Train Epoch: 67, Total Sample: 50000, Train Acc: 95.708, Test Acc: 81.220, Loss: 0.256, Total Time: 1369.026s\n",
      "Train Epoch: 68, Total Sample: 50000, Train Acc: 96.128, Test Acc: 81.240, Loss: 0.196, Total Time: 1389.065s\n",
      "Train Epoch: 69, Total Sample: 50000, Train Acc: 96.522, Test Acc: 81.740, Loss: 0.176, Total Time: 1409.149s\n",
      "Train Epoch: 70, Total Sample: 50000, Train Acc: 96.470, Test Acc: 81.280, Loss: 0.211, Total Time: 1429.416s\n",
      "Train Epoch: 71, Total Sample: 50000, Train Acc: 96.690, Test Acc: 81.830, Loss: 0.206, Total Time: 1449.594s\n",
      "Train Epoch: 72, Total Sample: 50000, Train Acc: 96.952, Test Acc: 81.690, Loss: 0.251, Total Time: 1469.750s\n",
      "Train Epoch: 73, Total Sample: 50000, Train Acc: 97.040, Test Acc: 81.540, Loss: 0.317, Total Time: 1489.981s\n",
      "Train Epoch: 74, Total Sample: 50000, Train Acc: 97.176, Test Acc: 81.320, Loss: 0.285, Total Time: 1510.221s\n",
      "Train Epoch: 75, Total Sample: 50000, Train Acc: 96.968, Test Acc: 81.280, Loss: 0.172, Total Time: 1530.387s\n",
      "Train Epoch: 76, Total Sample: 50000, Train Acc: 97.360, Test Acc: 81.840, Loss: 0.190, Total Time: 1550.604s\n",
      "Train Epoch: 77, Total Sample: 50000, Train Acc: 97.352, Test Acc: 81.540, Loss: 0.210, Total Time: 1570.898s\n",
      "Train Epoch: 78, Total Sample: 50000, Train Acc: 97.410, Test Acc: 81.700, Loss: 0.205, Total Time: 1591.098s\n",
      "Train Epoch: 79, Total Sample: 50000, Train Acc: 97.752, Test Acc: 81.890, Loss: 0.217, Total Time: 1611.284s\n",
      "Train Epoch: 80, Total Sample: 50000, Train Acc: 97.688, Test Acc: 81.560, Loss: 0.204, Total Time: 1631.487s\n",
      "Train Epoch: 81, Total Sample: 50000, Train Acc: 97.872, Test Acc: 82.160, Loss: 0.272, Total Time: 1651.720s\n",
      "Train Epoch: 82, Total Sample: 50000, Train Acc: 97.792, Test Acc: 81.700, Loss: 0.253, Total Time: 1671.862s\n",
      "Train Epoch: 83, Total Sample: 50000, Train Acc: 97.824, Test Acc: 82.130, Loss: 0.182, Total Time: 1692.080s\n",
      "Train Epoch: 84, Total Sample: 50000, Train Acc: 97.854, Test Acc: 82.080, Loss: 0.153, Total Time: 1712.247s\n",
      "Train Epoch: 85, Total Sample: 50000, Train Acc: 98.036, Test Acc: 81.560, Loss: 0.195, Total Time: 1732.404s\n",
      "Train Epoch: 86, Total Sample: 50000, Train Acc: 98.052, Test Acc: 81.640, Loss: 0.169, Total Time: 1752.671s\n",
      "Train Epoch: 87, Total Sample: 50000, Train Acc: 98.036, Test Acc: 82.180, Loss: 0.193, Total Time: 1773.341s\n",
      "Train Epoch: 88, Total Sample: 50000, Train Acc: 98.046, Test Acc: 81.720, Loss: 0.192, Total Time: 1794.624s\n",
      "Train Epoch: 89, Total Sample: 50000, Train Acc: 98.084, Test Acc: 81.990, Loss: 0.180, Total Time: 1815.949s\n",
      "Train Epoch: 90, Total Sample: 50000, Train Acc: 98.070, Test Acc: 82.180, Loss: 0.164, Total Time: 1836.820s\n",
      "Train Epoch: 91, Total Sample: 50000, Train Acc: 98.118, Test Acc: 81.920, Loss: 0.180, Total Time: 1857.767s\n",
      "Train Epoch: 92, Total Sample: 50000, Train Acc: 98.176, Test Acc: 81.990, Loss: 0.208, Total Time: 1878.713s\n",
      "Train Epoch: 93, Total Sample: 50000, Train Acc: 98.216, Test Acc: 82.320, Loss: 0.216, Total Time: 1899.496s\n",
      "Train Epoch: 94, Total Sample: 50000, Train Acc: 98.162, Test Acc: 82.120, Loss: 0.165, Total Time: 1919.749s\n",
      "Train Epoch: 95, Total Sample: 50000, Train Acc: 98.172, Test Acc: 82.060, Loss: 0.183, Total Time: 1939.892s\n",
      "Train Epoch: 96, Total Sample: 50000, Train Acc: 98.214, Test Acc: 82.020, Loss: 0.217, Total Time: 1960.121s\n",
      "Train Epoch: 97, Total Sample: 50000, Train Acc: 98.138, Test Acc: 82.240, Loss: 0.200, Total Time: 1980.305s\n",
      "Train Epoch: 98, Total Sample: 50000, Train Acc: 98.130, Test Acc: 82.130, Loss: 0.197, Total Time: 2000.544s\n",
      "Train Epoch: 99, Total Sample: 50000, Train Acc: 98.156, Test Acc: 82.010, Loss: 0.175, Total Time: 2020.954s\n",
      "Train Epoch: 100, Total Sample: 50000, Train Acc: 98.206, Test Acc: 81.890, Loss: 0.221, Total Time: 2041.285s\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "os.system(cmd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 54000  \t target_test: 6000\n",
      "Train Epoch: 2, Total Sample: 54000, Train Acc: 48.176, Test Acc: 47.350, Loss: 1.281, Total Time: 44.768s\n",
      "Train Epoch: 1, Total Sample: 54000, Train Acc: 44.793, Test Acc: 44.150, Loss: 1.519, Total Time: 23.419s\n",
      "Train Epoch: 3, Total Sample: 54000, Train Acc: 50.417, Test Acc: 50.267, Loss: 1.288, Total Time: 66.065s\n",
      "Train Epoch: 2, Total Sample: 54000, Train Acc: 48.176, Test Acc: 47.350, Loss: 1.281, Total Time: 44.504s\n",
      "Train Epoch: 4, Total Sample: 54000, Train Acc: 55.430, Test Acc: 54.867, Loss: 1.021, Total Time: 87.836s\n",
      "Train Epoch: 3, Total Sample: 54000, Train Acc: 50.417, Test Acc: 50.267, Loss: 1.288, Total Time: 65.772s\n",
      "Train Epoch: 5, Total Sample: 54000, Train Acc: 57.341, Test Acc: 56.933, Loss: 1.014, Total Time: 109.250s\n",
      "Train Epoch: 4, Total Sample: 54000, Train Acc: 55.430, Test Acc: 54.867, Loss: 1.021, Total Time: 87.629s\n",
      "Train Epoch: 6, Total Sample: 54000, Train Acc: 57.594, Test Acc: 56.567, Loss: 1.048, Total Time: 130.508s\n",
      "Train Epoch: 5, Total Sample: 54000, Train Acc: 57.341, Test Acc: 56.933, Loss: 1.014, Total Time: 108.775s\n",
      "Train Epoch: 7, Total Sample: 54000, Train Acc: 61.091, Test Acc: 59.933, Loss: 1.155, Total Time: 151.709s\n",
      "Train Epoch: 6, Total Sample: 54000, Train Acc: 57.594, Test Acc: 56.567, Loss: 1.048, Total Time: 130.429s\n",
      "Train Epoch: 8, Total Sample: 54000, Train Acc: 58.285, Test Acc: 56.367, Loss: 1.082, Total Time: 172.968s\n",
      "Train Epoch: 7, Total Sample: 54000, Train Acc: 61.091, Test Acc: 59.933, Loss: 1.155, Total Time: 151.712s\n",
      "Train Epoch: 9, Total Sample: 54000, Train Acc: 64.102, Test Acc: 62.300, Loss: 0.825, Total Time: 194.143s\n",
      "Train Epoch: 8, Total Sample: 54000, Train Acc: 58.285, Test Acc: 56.367, Loss: 1.082, Total Time: 173.089s\n",
      "Train Epoch: 10, Total Sample: 54000, Train Acc: 64.826, Test Acc: 63.133, Loss: 1.092, Total Time: 215.428s\n",
      "Train Epoch: 9, Total Sample: 54000, Train Acc: 64.102, Test Acc: 62.300, Loss: 0.825, Total Time: 194.463s\n",
      "Train Epoch: 11, Total Sample: 54000, Train Acc: 67.957, Test Acc: 65.900, Loss: 1.036, Total Time: 236.788s\n",
      "Train Epoch: 10, Total Sample: 54000, Train Acc: 64.826, Test Acc: 63.133, Loss: 1.092, Total Time: 215.600s\n",
      "Train Epoch: 12, Total Sample: 54000, Train Acc: 70.309, Test Acc: 69.100, Loss: 0.782, Total Time: 258.724s\n",
      "Train Epoch: 11, Total Sample: 54000, Train Acc: 67.957, Test Acc: 65.900, Loss: 1.036, Total Time: 237.435s\n",
      "Train Epoch: 13, Total Sample: 54000, Train Acc: 71.541, Test Acc: 69.167, Loss: 0.682, Total Time: 279.938s\n",
      "Train Epoch: 12, Total Sample: 54000, Train Acc: 70.309, Test Acc: 69.100, Loss: 0.782, Total Time: 258.507s\n",
      "Train Epoch: 14, Total Sample: 54000, Train Acc: 63.861, Test Acc: 62.183, Loss: 0.804, Total Time: 301.071s\n",
      "Train Epoch: 13, Total Sample: 54000, Train Acc: 71.541, Test Acc: 69.167, Loss: 0.682, Total Time: 279.630s\n",
      "Train Epoch: 15, Total Sample: 54000, Train Acc: 73.074, Test Acc: 70.433, Loss: 0.515, Total Time: 322.243s\n",
      "Train Epoch: 14, Total Sample: 54000, Train Acc: 63.861, Test Acc: 62.183, Loss: 0.804, Total Time: 300.731s\n",
      "Train Epoch: 16, Total Sample: 54000, Train Acc: 72.643, Test Acc: 70.383, Loss: 0.770, Total Time: 344.021s\n",
      "Train Epoch: 15, Total Sample: 54000, Train Acc: 73.074, Test Acc: 70.433, Loss: 0.515, Total Time: 321.817s\n",
      "Train Epoch: 17, Total Sample: 54000, Train Acc: 72.861, Test Acc: 70.233, Loss: 0.709, Total Time: 365.881s\n",
      "Train Epoch: 16, Total Sample: 54000, Train Acc: 72.643, Test Acc: 70.383, Loss: 0.770, Total Time: 342.817s\n",
      "Train Epoch: 18, Total Sample: 54000, Train Acc: 72.961, Test Acc: 68.700, Loss: 0.693, Total Time: 387.156s\n",
      "Train Epoch: 17, Total Sample: 54000, Train Acc: 72.861, Test Acc: 70.233, Loss: 0.709, Total Time: 363.911s\n",
      "Train Epoch: 19, Total Sample: 54000, Train Acc: 68.543, Test Acc: 65.700, Loss: 0.829, Total Time: 408.253s\n",
      "Train Epoch: 18, Total Sample: 54000, Train Acc: 72.961, Test Acc: 68.700, Loss: 0.693, Total Time: 385.075s\n",
      "Train Epoch: 20, Total Sample: 54000, Train Acc: 74.331, Test Acc: 71.217, Loss: 0.565, Total Time: 429.550s\n",
      "Train Epoch: 19, Total Sample: 54000, Train Acc: 68.543, Test Acc: 65.700, Loss: 0.829, Total Time: 406.367s\n",
      "Train Epoch: 21, Total Sample: 54000, Train Acc: 75.219, Test Acc: 71.550, Loss: 0.681, Total Time: 450.779s\n",
      "Train Epoch: 20, Total Sample: 54000, Train Acc: 74.331, Test Acc: 71.217, Loss: 0.565, Total Time: 427.437s\n",
      "Train Epoch: 22, Total Sample: 54000, Train Acc: 75.337, Test Acc: 71.517, Loss: 0.679, Total Time: 472.218s\n",
      "Train Epoch: 21, Total Sample: 54000, Train Acc: 75.219, Test Acc: 71.550, Loss: 0.681, Total Time: 449.159s\n",
      "Train Epoch: 23, Total Sample: 54000, Train Acc: 76.633, Test Acc: 72.550, Loss: 0.520, Total Time: 493.439s\n",
      "Train Epoch: 22, Total Sample: 54000, Train Acc: 75.337, Test Acc: 71.517, Loss: 0.679, Total Time: 470.976s\n",
      "Train Epoch: 24, Total Sample: 54000, Train Acc: 76.015, Test Acc: 71.250, Loss: 0.563, Total Time: 514.622s\n",
      "Train Epoch: 23, Total Sample: 54000, Train Acc: 76.633, Test Acc: 72.550, Loss: 0.520, Total Time: 491.963s\n",
      "Train Epoch: 25, Total Sample: 54000, Train Acc: 77.748, Test Acc: 72.750, Loss: 0.701, Total Time: 535.796s\n",
      "Train Epoch: 24, Total Sample: 54000, Train Acc: 76.015, Test Acc: 71.250, Loss: 0.563, Total Time: 512.921s\n",
      "Train Epoch: 26, Total Sample: 54000, Train Acc: 78.056, Test Acc: 73.050, Loss: 0.529, Total Time: 557.001s\n",
      "Train Epoch: 25, Total Sample: 54000, Train Acc: 77.748, Test Acc: 72.750, Loss: 0.701, Total Time: 534.032s\n",
      "Train Epoch: 27, Total Sample: 54000, Train Acc: 79.883, Test Acc: 74.800, Loss: 0.655, Total Time: 578.171s\n",
      "Train Epoch: 26, Total Sample: 54000, Train Acc: 78.056, Test Acc: 73.050, Loss: 0.529, Total Time: 555.185s\n",
      "Train Epoch: 28, Total Sample: 54000, Train Acc: 78.094, Test Acc: 72.850, Loss: 0.434, Total Time: 599.932s\n",
      "Train Epoch: 27, Total Sample: 54000, Train Acc: 79.883, Test Acc: 74.800, Loss: 0.655, Total Time: 576.325s\n",
      "Train Epoch: 29, Total Sample: 54000, Train Acc: 77.924, Test Acc: 72.817, Loss: 0.533, Total Time: 621.820s\n",
      "Train Epoch: 28, Total Sample: 54000, Train Acc: 78.094, Test Acc: 72.850, Loss: 0.434, Total Time: 597.359s\n",
      "Train Epoch: 30, Total Sample: 54000, Train Acc: 81.776, Test Acc: 75.283, Loss: 0.598, Total Time: 643.640s\n",
      "Train Epoch: 29, Total Sample: 54000, Train Acc: 77.924, Test Acc: 72.817, Loss: 0.533, Total Time: 618.438s\n",
      "Train Epoch: 31, Total Sample: 54000, Train Acc: 77.080, Test Acc: 72.217, Loss: 0.591, Total Time: 664.820s\n",
      "Train Epoch: 30, Total Sample: 54000, Train Acc: 81.776, Test Acc: 75.283, Loss: 0.598, Total Time: 639.632s\n",
      "Train Epoch: 32, Total Sample: 54000, Train Acc: 80.880, Test Acc: 75.267, Loss: 0.506, Total Time: 685.945s\n",
      "Train Epoch: 31, Total Sample: 54000, Train Acc: 77.080, Test Acc: 72.217, Loss: 0.591, Total Time: 660.851s\n",
      "Train Epoch: 33, Total Sample: 54000, Train Acc: 80.237, Test Acc: 73.633, Loss: 0.564, Total Time: 707.163s\n",
      "Train Epoch: 32, Total Sample: 54000, Train Acc: 80.880, Test Acc: 75.267, Loss: 0.506, Total Time: 681.752s\n",
      "Train Epoch: 34, Total Sample: 54000, Train Acc: 80.852, Test Acc: 74.250, Loss: 0.474, Total Time: 728.910s\n",
      "Train Epoch: 33, Total Sample: 54000, Train Acc: 80.237, Test Acc: 73.633, Loss: 0.564, Total Time: 702.759s\n",
      "Train Epoch: 35, Total Sample: 54000, Train Acc: 80.020, Test Acc: 73.667, Loss: 0.473, Total Time: 750.129s\n",
      "Train Epoch: 34, Total Sample: 54000, Train Acc: 80.852, Test Acc: 74.250, Loss: 0.474, Total Time: 724.511s\n",
      "Train Epoch: 36, Total Sample: 54000, Train Acc: 81.837, Test Acc: 74.600, Loss: 0.461, Total Time: 771.331s\n",
      "Train Epoch: 35, Total Sample: 54000, Train Acc: 80.020, Test Acc: 73.667, Loss: 0.473, Total Time: 745.995s\n",
      "Train Epoch: 37, Total Sample: 54000, Train Acc: 82.687, Test Acc: 75.033, Loss: 0.570, Total Time: 793.201s\n",
      "Train Epoch: 36, Total Sample: 54000, Train Acc: 81.837, Test Acc: 74.600, Loss: 0.461, Total Time: 767.098s\n",
      "Train Epoch: 38, Total Sample: 54000, Train Acc: 80.367, Test Acc: 73.100, Loss: 0.494, Total Time: 814.490s\n",
      "Train Epoch: 37, Total Sample: 54000, Train Acc: 82.687, Test Acc: 75.033, Loss: 0.570, Total Time: 788.207s\n",
      "Train Epoch: 39, Total Sample: 54000, Train Acc: 83.548, Test Acc: 75.867, Loss: 0.572, Total Time: 835.772s\n",
      "Train Epoch: 38, Total Sample: 54000, Train Acc: 80.367, Test Acc: 73.100, Loss: 0.494, Total Time: 809.312s\n",
      "Train Epoch: 40, Total Sample: 54000, Train Acc: 78.628, Test Acc: 71.883, Loss: 0.472, Total Time: 857.009s\n",
      "Train Epoch: 39, Total Sample: 54000, Train Acc: 83.548, Test Acc: 75.867, Loss: 0.572, Total Time: 830.410s\n",
      "Train Epoch: 41, Total Sample: 54000, Train Acc: 82.659, Test Acc: 75.117, Loss: 0.430, Total Time: 878.771s\n",
      "Train Epoch: 40, Total Sample: 54000, Train Acc: 78.628, Test Acc: 71.883, Loss: 0.472, Total Time: 851.483s\n",
      "Train Epoch: 42, Total Sample: 54000, Train Acc: 85.228, Test Acc: 77.017, Loss: 0.407, Total Time: 900.088s\n",
      "Train Epoch: 41, Total Sample: 54000, Train Acc: 82.659, Test Acc: 75.117, Loss: 0.430, Total Time: 872.661s\n",
      "Train Epoch: 43, Total Sample: 54000, Train Acc: 85.731, Test Acc: 76.900, Loss: 0.471, Total Time: 921.316s\n",
      "Train Epoch: 42, Total Sample: 54000, Train Acc: 85.228, Test Acc: 77.017, Loss: 0.407, Total Time: 893.773s\n",
      "Train Epoch: 44, Total Sample: 54000, Train Acc: 85.617, Test Acc: 77.017, Loss: 0.368, Total Time: 942.515s\n",
      "Train Epoch: 43, Total Sample: 54000, Train Acc: 85.731, Test Acc: 76.900, Loss: 0.471, Total Time: 914.856s\n",
      "Train Epoch: 45, Total Sample: 54000, Train Acc: 86.181, Test Acc: 76.883, Loss: 0.543, Total Time: 963.675s\n",
      "Train Epoch: 44, Total Sample: 54000, Train Acc: 85.617, Test Acc: 77.017, Loss: 0.368, Total Time: 935.942s\n",
      "Train Epoch: 46, Total Sample: 54000, Train Acc: 85.726, Test Acc: 75.833, Loss: 0.500, Total Time: 984.966s\n",
      "Train Epoch: 45, Total Sample: 54000, Train Acc: 86.181, Test Acc: 76.883, Loss: 0.543, Total Time: 957.022s\n",
      "Train Epoch: 47, Total Sample: 54000, Train Acc: 85.469, Test Acc: 75.850, Loss: 0.446, Total Time: 1006.137s\n",
      "Train Epoch: 46, Total Sample: 54000, Train Acc: 85.726, Test Acc: 75.833, Loss: 0.500, Total Time: 978.014s\n",
      "Train Epoch: 48, Total Sample: 54000, Train Acc: 86.106, Test Acc: 76.317, Loss: 0.389, Total Time: 1027.196s\n",
      "Train Epoch: 47, Total Sample: 54000, Train Acc: 85.469, Test Acc: 75.850, Loss: 0.446, Total Time: 1000.381s\n",
      "Train Epoch: 49, Total Sample: 54000, Train Acc: 87.700, Test Acc: 77.617, Loss: 0.346, Total Time: 1048.299s\n",
      "Train Epoch: 48, Total Sample: 54000, Train Acc: 86.106, Test Acc: 76.317, Loss: 0.389, Total Time: 1023.327s\n",
      "Train Epoch: 50, Total Sample: 54000, Train Acc: 87.624, Test Acc: 77.100, Loss: 0.443, Total Time: 1069.477s\n",
      "Train Epoch: 49, Total Sample: 54000, Train Acc: 87.700, Test Acc: 77.617, Loss: 0.346, Total Time: 1045.071s\n",
      "Train Epoch: 51, Total Sample: 54000, Train Acc: 88.119, Test Acc: 77.750, Loss: 0.447, Total Time: 1090.696s\n",
      "Train Epoch: 50, Total Sample: 54000, Train Acc: 87.624, Test Acc: 77.100, Loss: 0.443, Total Time: 1066.045s\n",
      "Train Epoch: 52, Total Sample: 54000, Train Acc: 87.337, Test Acc: 76.883, Loss: 0.416, Total Time: 1111.983s\n",
      "Train Epoch: 51, Total Sample: 54000, Train Acc: 88.119, Test Acc: 77.750, Loss: 0.447, Total Time: 1087.028s\n",
      "Train Epoch: 53, Total Sample: 54000, Train Acc: 88.446, Test Acc: 77.867, Loss: 0.256, Total Time: 1133.227s\n",
      "Train Epoch: 52, Total Sample: 54000, Train Acc: 87.337, Test Acc: 76.883, Loss: 0.416, Total Time: 1108.077s\n",
      "Train Epoch: 54, Total Sample: 54000, Train Acc: 88.531, Test Acc: 76.733, Loss: 0.291, Total Time: 1154.480s\n",
      "Train Epoch: 53, Total Sample: 54000, Train Acc: 88.446, Test Acc: 77.867, Loss: 0.256, Total Time: 1129.086s\n",
      "Train Epoch: 55, Total Sample: 54000, Train Acc: 89.126, Test Acc: 78.450, Loss: 0.358, Total Time: 1175.741s\n",
      "Train Epoch: 54, Total Sample: 54000, Train Acc: 88.531, Test Acc: 76.733, Loss: 0.291, Total Time: 1150.063s\n",
      "Train Epoch: 56, Total Sample: 54000, Train Acc: 88.622, Test Acc: 77.067, Loss: 0.421, Total Time: 1196.936s\n",
      "Train Epoch: 55, Total Sample: 54000, Train Acc: 89.126, Test Acc: 78.450, Loss: 0.358, Total Time: 1171.184s\n",
      "Train Epoch: 57, Total Sample: 54000, Train Acc: 89.965, Test Acc: 78.050, Loss: 0.336, Total Time: 1218.188s\n",
      "Train Epoch: 56, Total Sample: 54000, Train Acc: 88.622, Test Acc: 77.067, Loss: 0.421, Total Time: 1192.253s\n",
      "Train Epoch: 58, Total Sample: 54000, Train Acc: 90.217, Test Acc: 77.567, Loss: 0.240, Total Time: 1239.425s\n",
      "Train Epoch: 57, Total Sample: 54000, Train Acc: 89.965, Test Acc: 78.050, Loss: 0.336, Total Time: 1213.247s\n",
      "Train Epoch: 59, Total Sample: 54000, Train Acc: 89.852, Test Acc: 77.550, Loss: 0.262, Total Time: 1260.646s\n",
      "Train Epoch: 58, Total Sample: 54000, Train Acc: 90.217, Test Acc: 77.567, Loss: 0.240, Total Time: 1234.240s\n",
      "Train Epoch: 60, Total Sample: 54000, Train Acc: 90.398, Test Acc: 77.150, Loss: 0.318, Total Time: 1281.803s\n",
      "Train Epoch: 59, Total Sample: 54000, Train Acc: 89.852, Test Acc: 77.550, Loss: 0.262, Total Time: 1255.218s\n",
      "Train Epoch: 61, Total Sample: 54000, Train Acc: 91.150, Test Acc: 78.350, Loss: 0.260, Total Time: 1302.960s\n",
      "Train Epoch: 60, Total Sample: 54000, Train Acc: 90.398, Test Acc: 77.150, Loss: 0.318, Total Time: 1276.319s\n",
      "Train Epoch: 62, Total Sample: 54000, Train Acc: 91.369, Test Acc: 77.600, Loss: 0.317, Total Time: 1324.206s\n",
      "Train Epoch: 61, Total Sample: 54000, Train Acc: 91.150, Test Acc: 78.350, Loss: 0.260, Total Time: 1297.434s\n",
      "Train Epoch: 63, Total Sample: 54000, Train Acc: 91.085, Test Acc: 78.050, Loss: 0.301, Total Time: 1346.088s\n",
      "Train Epoch: 62, Total Sample: 54000, Train Acc: 91.369, Test Acc: 77.600, Loss: 0.317, Total Time: 1318.483s\n",
      "Train Epoch: 64, Total Sample: 54000, Train Acc: 91.333, Test Acc: 78.067, Loss: 0.181, Total Time: 1367.224s\n",
      "Train Epoch: 63, Total Sample: 54000, Train Acc: 91.085, Test Acc: 78.050, Loss: 0.301, Total Time: 1340.150s\n",
      "Train Epoch: 65, Total Sample: 54000, Train Acc: 91.494, Test Acc: 78.183, Loss: 0.307, Total Time: 1388.487s\n",
      "Train Epoch: 64, Total Sample: 54000, Train Acc: 91.333, Test Acc: 78.067, Loss: 0.181, Total Time: 1361.133s\n",
      "Train Epoch: 66, Total Sample: 54000, Train Acc: 92.267, Test Acc: 78.683, Loss: 0.309, Total Time: 1410.640s\n",
      "Train Epoch: 65, Total Sample: 54000, Train Acc: 91.494, Test Acc: 78.183, Loss: 0.307, Total Time: 1382.109s\n",
      "Train Epoch: 67, Total Sample: 54000, Train Acc: 92.337, Test Acc: 78.517, Loss: 0.216, Total Time: 1433.142s\n",
      "Train Epoch: 66, Total Sample: 54000, Train Acc: 92.267, Test Acc: 78.683, Loss: 0.309, Total Time: 1403.126s\n",
      "Train Epoch: 68, Total Sample: 54000, Train Acc: 92.302, Test Acc: 78.200, Loss: 0.108, Total Time: 1454.824s\n",
      "Train Epoch: 67, Total Sample: 54000, Train Acc: 92.337, Test Acc: 78.517, Loss: 0.216, Total Time: 1424.233s\n",
      "Train Epoch: 69, Total Sample: 54000, Train Acc: 92.444, Test Acc: 78.300, Loss: 0.238, Total Time: 1475.916s\n",
      "Train Epoch: 68, Total Sample: 54000, Train Acc: 92.302, Test Acc: 78.200, Loss: 0.108, Total Time: 1445.212s\n",
      "Train Epoch: 70, Total Sample: 54000, Train Acc: 92.737, Test Acc: 79.733, Loss: 0.261, Total Time: 1497.141s\n",
      "Train Epoch: 69, Total Sample: 54000, Train Acc: 92.444, Test Acc: 78.300, Loss: 0.238, Total Time: 1466.311s\n",
      "Train Epoch: 71, Total Sample: 54000, Train Acc: 93.237, Test Acc: 78.583, Loss: 0.253, Total Time: 1518.355s\n",
      "Train Epoch: 70, Total Sample: 54000, Train Acc: 92.737, Test Acc: 79.733, Loss: 0.261, Total Time: 1488.025s\n",
      "Train Epoch: 72, Total Sample: 54000, Train Acc: 93.311, Test Acc: 78.283, Loss: 0.275, Total Time: 1539.520s\n",
      "Train Epoch: 71, Total Sample: 54000, Train Acc: 93.237, Test Acc: 78.583, Loss: 0.253, Total Time: 1509.229s\n",
      "Train Epoch: 73, Total Sample: 54000, Train Acc: 93.672, Test Acc: 78.900, Loss: 0.295, Total Time: 1560.635s\n",
      "Train Epoch: 72, Total Sample: 54000, Train Acc: 93.311, Test Acc: 78.283, Loss: 0.275, Total Time: 1530.366s\n",
      "Train Epoch: 74, Total Sample: 54000, Train Acc: 93.287, Test Acc: 78.900, Loss: 0.297, Total Time: 1581.792s\n",
      "Train Epoch: 73, Total Sample: 54000, Train Acc: 93.672, Test Acc: 78.900, Loss: 0.295, Total Time: 1551.526s\n",
      "Train Epoch: 75, Total Sample: 54000, Train Acc: 93.972, Test Acc: 78.817, Loss: 0.252, Total Time: 1602.983s\n",
      "Train Epoch: 74, Total Sample: 54000, Train Acc: 93.287, Test Acc: 78.900, Loss: 0.297, Total Time: 1572.518s\n",
      "Train Epoch: 76, Total Sample: 54000, Train Acc: 94.113, Test Acc: 78.950, Loss: 0.152, Total Time: 1624.330s\n",
      "Train Epoch: 75, Total Sample: 54000, Train Acc: 93.972, Test Acc: 78.817, Loss: 0.252, Total Time: 1593.493s\n",
      "Train Epoch: 77, Total Sample: 54000, Train Acc: 94.124, Test Acc: 78.833, Loss: 0.204, Total Time: 1645.622s\n",
      "Train Epoch: 76, Total Sample: 54000, Train Acc: 94.113, Test Acc: 78.950, Loss: 0.152, Total Time: 1614.892s\n",
      "Train Epoch: 78, Total Sample: 54000, Train Acc: 93.987, Test Acc: 79.050, Loss: 0.218, Total Time: 1666.777s\n",
      "Train Epoch: 77, Total Sample: 54000, Train Acc: 94.124, Test Acc: 78.833, Loss: 0.204, Total Time: 1636.564s\n",
      "Train Epoch: 79, Total Sample: 54000, Train Acc: 94.178, Test Acc: 78.967, Loss: 0.177, Total Time: 1687.901s\n",
      "Train Epoch: 78, Total Sample: 54000, Train Acc: 93.987, Test Acc: 79.050, Loss: 0.218, Total Time: 1657.613s\n",
      "Train Epoch: 80, Total Sample: 54000, Train Acc: 94.470, Test Acc: 79.167, Loss: 0.149, Total Time: 1709.119s\n",
      "Train Epoch: 79, Total Sample: 54000, Train Acc: 94.178, Test Acc: 78.967, Loss: 0.177, Total Time: 1678.518s\n",
      "Train Epoch: 81, Total Sample: 54000, Train Acc: 94.667, Test Acc: 78.517, Loss: 0.252, Total Time: 1731.024s\n",
      "Train Epoch: 80, Total Sample: 54000, Train Acc: 94.470, Test Acc: 79.167, Loss: 0.149, Total Time: 1699.536s\n",
      "Train Epoch: 82, Total Sample: 54000, Train Acc: 94.765, Test Acc: 78.850, Loss: 0.202, Total Time: 1752.918s\n",
      "Train Epoch: 81, Total Sample: 54000, Train Acc: 94.667, Test Acc: 78.517, Loss: 0.252, Total Time: 1720.536s\n",
      "Train Epoch: 83, Total Sample: 54000, Train Acc: 94.783, Test Acc: 78.533, Loss: 0.235, Total Time: 1774.096s\n",
      "Train Epoch: 82, Total Sample: 54000, Train Acc: 94.765, Test Acc: 78.850, Loss: 0.202, Total Time: 1741.521s\n",
      "Train Epoch: 84, Total Sample: 54000, Train Acc: 94.935, Test Acc: 79.617, Loss: 0.248, Total Time: 1795.288s\n",
      "Train Epoch: 83, Total Sample: 54000, Train Acc: 94.783, Test Acc: 78.533, Loss: 0.235, Total Time: 1762.535s\n",
      "Train Epoch: 85, Total Sample: 54000, Train Acc: 94.913, Test Acc: 78.967, Loss: 0.149, Total Time: 1816.585s\n",
      "Train Epoch: 84, Total Sample: 54000, Train Acc: 94.935, Test Acc: 79.617, Loss: 0.248, Total Time: 1783.556s\n",
      "Train Epoch: 86, Total Sample: 54000, Train Acc: 95.113, Test Acc: 79.183, Loss: 0.270, Total Time: 1837.755s\n",
      "Train Epoch: 85, Total Sample: 54000, Train Acc: 94.913, Test Acc: 78.967, Loss: 0.149, Total Time: 1804.535s\n",
      "Train Epoch: 87, Total Sample: 54000, Train Acc: 95.096, Test Acc: 78.400, Loss: 0.111, Total Time: 1858.984s\n",
      "Train Epoch: 86, Total Sample: 54000, Train Acc: 95.113, Test Acc: 79.183, Loss: 0.270, Total Time: 1825.546s\n",
      "Train Epoch: 88, Total Sample: 54000, Train Acc: 95.243, Test Acc: 78.917, Loss: 0.240, Total Time: 1880.225s\n",
      "Train Epoch: 87, Total Sample: 54000, Train Acc: 95.096, Test Acc: 78.400, Loss: 0.111, Total Time: 1846.603s\n",
      "Train Epoch: 89, Total Sample: 54000, Train Acc: 95.363, Test Acc: 78.650, Loss: 0.160, Total Time: 1901.508s\n",
      "Train Epoch: 88, Total Sample: 54000, Train Acc: 95.243, Test Acc: 78.917, Loss: 0.240, Total Time: 1868.482s\n",
      "Train Epoch: 90, Total Sample: 54000, Train Acc: 95.322, Test Acc: 79.217, Loss: 0.155, Total Time: 1922.660s\n",
      "Train Epoch: 89, Total Sample: 54000, Train Acc: 95.363, Test Acc: 78.650, Loss: 0.160, Total Time: 1890.807s\n",
      "Train Epoch: 91, Total Sample: 54000, Train Acc: 95.226, Test Acc: 79.533, Loss: 0.177, Total Time: 1943.930s\n",
      "Train Epoch: 90, Total Sample: 54000, Train Acc: 95.322, Test Acc: 79.217, Loss: 0.155, Total Time: 1913.145s\n",
      "Train Epoch: 92, Total Sample: 54000, Train Acc: 95.420, Test Acc: 79.383, Loss: 0.109, Total Time: 1965.134s\n",
      "Train Epoch: 91, Total Sample: 54000, Train Acc: 95.226, Test Acc: 79.533, Loss: 0.177, Total Time: 1934.142s\n",
      "Train Epoch: 93, Total Sample: 54000, Train Acc: 95.257, Test Acc: 78.733, Loss: 0.201, Total Time: 1986.359s\n",
      "Train Epoch: 92, Total Sample: 54000, Train Acc: 95.420, Test Acc: 79.383, Loss: 0.109, Total Time: 1955.901s\n",
      "Train Epoch: 94, Total Sample: 54000, Train Acc: 95.413, Test Acc: 79.467, Loss: 0.174, Total Time: 2007.602s\n",
      "Train Epoch: 93, Total Sample: 54000, Train Acc: 95.257, Test Acc: 78.733, Loss: 0.201, Total Time: 1977.627s\n",
      "Train Epoch: 95, Total Sample: 54000, Train Acc: 95.387, Test Acc: 78.750, Loss: 0.236, Total Time: 2028.863s\n",
      "Train Epoch: 94, Total Sample: 54000, Train Acc: 95.413, Test Acc: 79.467, Loss: 0.174, Total Time: 1998.738s\n",
      "Train Epoch: 96, Total Sample: 54000, Train Acc: 95.369, Test Acc: 79.467, Loss: 0.116, Total Time: 2049.978s\n",
      "Train Epoch: 95, Total Sample: 54000, Train Acc: 95.387, Test Acc: 78.750, Loss: 0.236, Total Time: 2019.774s\n",
      "Train Epoch: 97, Total Sample: 54000, Train Acc: 95.417, Test Acc: 79.100, Loss: 0.367, Total Time: 2071.176s\n",
      "Train Epoch: 96, Total Sample: 54000, Train Acc: 95.369, Test Acc: 79.467, Loss: 0.116, Total Time: 2040.820s\n",
      "Train Epoch: 98, Total Sample: 54000, Train Acc: 95.443, Test Acc: 79.100, Loss: 0.173, Total Time: 2092.372s\n",
      "Train Epoch: 97, Total Sample: 54000, Train Acc: 95.417, Test Acc: 79.100, Loss: 0.367, Total Time: 2061.924s\n",
      "Train Epoch: 99, Total Sample: 54000, Train Acc: 95.320, Test Acc: 79.283, Loss: 0.217, Total Time: 2113.514s\n",
      "Train Epoch: 98, Total Sample: 54000, Train Acc: 95.443, Test Acc: 79.100, Loss: 0.173, Total Time: 2083.002s\n",
      "Train Epoch: 100, Total Sample: 54000, Train Acc: 95.374, Test Acc: 78.933, Loss: 0.315, Total Time: 2134.718s\n",
      "Finish Training\n",
      "Train Epoch: 99, Total Sample: 54000, Train Acc: 95.320, Test Acc: 79.283, Loss: 0.217, Total Time: 2103.999s\n",
      "Train Epoch: 100, Total Sample: 54000, Train Acc: 95.374, Test Acc: 78.933, Loss: 0.315, Total Time: 2124.979s\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成！\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "log_file = \"save/CIFAR10/NormalLoss/shadow/1/flood/logging.log\"\n",
    "csv_file = \"save/CIFAR10/NormalLoss/shadow/1/flood/log.csv\"\n",
    "\n",
    "# 打开日志文件和CSV文件\n",
    "with open(log_file, \"r\") as file:\n",
    "    with open(csv_file, \"w\", newline=\"\") as csv_output:\n",
    "        writer = csv.writer(csv_output)\n",
    "\n",
    "        # 写入CSV文件的标题行\n",
    "        writer.writerow([\"Train Epoch\", \"Total Sample\", \"Train Acc\", \"Test Acc\", \"Loss\", \"Total Time\"])\n",
    "\n",
    "        # 逐行读取日志文件并写入CSV文件\n",
    "        for line in file:\n",
    "            # 解析日志行\n",
    "            values = line.strip().split(\", \")\n",
    "            epoch = values[0].split(\": \")[1]\n",
    "            sample = values[1].split(\": \")[1]\n",
    "            train_acc = values[2].split(\": \")[1]\n",
    "            test_acc = values[3].split(\": \")[1]\n",
    "            loss = values[4].split(\": \")[1]\n",
    "            total_time = values[5].split(\": \")[1][:-1]\n",
    "\n",
    "            # 将解析的值写入CSV文件\n",
    "            writer.writerow([epoch, sample, train_acc, test_acc, loss, total_time])\n",
    "\n",
    "print(\"转换完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "转换完成！\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "log_file = \"save/CIFAR10/NormalLoss/shadow/1/flood/logging.log\"\n",
    "csv_file = \"save/CIFAR10/NormalLoss/shadow/1/flood/log.csv\"\n",
    "\n",
    "# 打开日志文件和CSV文件\n",
    "with open(log_file, \"r\") as file:\n",
    "    with open(csv_file, \"w\", newline=\"\") as csv_output:\n",
    "        writer = csv.writer(csv_output)\n",
    "\n",
    "        # 写入CSV文件的标题行\n",
    "        writer.writerow([\"Train Epoch\", \"Total Sample\", \"Train Acc\", \"Test Acc\", \"Loss\", \"Total Time\"])\n",
    "\n",
    "        # 读取日志文件的最后一行\n",
    "        last_line = file.readlines()[-1]\n",
    "        \n",
    "        # 解析最后一行\n",
    "        values = last_line.strip().split(\", \")\n",
    "        epoch = values[0].split(\": \")[1]\n",
    "        sample = values[1].split(\": \")[1]\n",
    "        train_acc = values[2].split(\": \")[1]\n",
    "        test_acc = values[3].split(\": \")[1]\n",
    "        loss = values[4].split(\": \")[1]\n",
    "        total_time = values[5].split(\": \")[1][:-1]\n",
    "\n",
    "        # 将解析的值写入CSV文件\n",
    "        writer.writerow([epoch, sample, train_acc, test_acc, loss, total_time])\n",
    "\n",
    "print(\"转换完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([0,1,2,4,5,6,2])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 94, Total Sample: 10000, Train Acc: 9.780, Test Acc: 10.240, Total Time: 564.616s\n",
      "Train Epoch: 95, Total Sample: 10000, Train Acc: 10.110, Test Acc: 10.550, Total Time: 570.704s\n",
      "Train Epoch: 96, Total Sample: 10000, Train Acc: 10.300, Test Acc: 9.290, Total Time: 576.753s\n",
      "Train Epoch: 97, Total Sample: 10000, Train Acc: 10.590, Test Acc: 10.130, Total Time: 582.746s\n",
      "Train Epoch: 98, Total Sample: 10000, Train Acc: 10.670, Test Acc: 10.150, Total Time: 588.774s\n",
      "Train Epoch: 99, Total Sample: 10000, Train Acc: 10.620, Test Acc: 10.120, Total Time: 594.916s\n",
      "Train Epoch: 100, Total Sample: 10000, Train Acc: 10.590, Test Acc: 10.110, Total Time: 600.928s\n",
      "Finish Training\n"
     ]
    }
   ],
   "source": [
    "temp = 0.1\n",
    "training_type = 'NormalLoss'\n",
    "loss_type = 'gce'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-16.11809565095832"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(10**(-7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(prob, label):\n",
    "    # 避免概率值为0，加上一个很小的值进行平滑处理\n",
    "    epsilon = 1e-12\n",
    "\n",
    "    # 使用np.clip确保概率值不为0或1，以避免log(0)或log(1)出现无效值\n",
    "    prob = np.clip(prob, epsilon, 1.0 - epsilon)\n",
    "\n",
    "    # 将label转换为one-hot编码\n",
    "    one_hot_label = np.zeros_like(prob)\n",
    "    one_hot_label[np.arange(len(label)), label] = 1\n",
    "\n",
    "    return -np.sum(one_hot_label * np.log(prob), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.64452637 3.46149949 0.33261234]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n =3\n",
    "prob = np.random.rand(n, 10)\n",
    "\n",
    "# 示例的真实标签数组（15000个样本，每个样本是一个类的索引，范围为0到9）\n",
    "label = np.random.randint(0, 10, size=n)\n",
    "\n",
    "cross_entropy_loss = cross_entropy(prob, label)\n",
    "\n",
    "print(cross_entropy_loss)\n",
    "print(cross_entropy_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8958797346140275"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.log(np.sqrt(1/2))+ np.log(np.sqrt(1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12975651199692184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(1/2)-np.sqrt(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666669"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/2-1/3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-hospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
