{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/liuzhenlong/MIA/MLHospital/mlh/')\n",
    "sys.path.append('/home/liuzhenlong/MIA/MLHospital/mlh/defenses')\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from defenses.membership_inference.AdvReg import TrainTargetAdvReg\n",
    "from defenses.membership_inference.DPSGD import TrainTargetDP\n",
    "from defenses.membership_inference.LabelSmoothing import TrainTargetLabelSmoothing\n",
    "from defenses.membership_inference.MixupMMD import TrainTargetMixupMMD\n",
    "from defenses.membership_inference.PATE import TrainTargetPATE\n",
    "from defenses.membership_inference.Normal import TrainTargetNormal\n",
    "\n",
    "from defenses.membership_inference.logit_norm import TrainTargetLogitsNorm\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data_preprocessing.data_loader import GetDataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: zzz2\n",
      "age: 19 weight: 58\n",
      "lzl3\n",
      "55\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: zzz2\n",
      "age: 25 weight: 58\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "name: lzl\n",
      "age: 18 sex: f\n",
      "name: zzz\n",
      "age: 19 sex: f\n",
      "25\n",
      "f\n",
      "name: abc\n",
      "age: 11 weight: 88\n",
      "name: 11\n",
      "age: 20 weight: abc2\n",
      "name: zzz2\n",
      "age: 20 weight: 58\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "class Admin(User):\n",
    "    def __init__(self,weight,name='zzz2',age=20):\n",
    "        super().__init__(name,age)#因为此处要用父类的sex初值，所以就无须提供sex的值了\n",
    "        self.weight = weight\n",
    "    def show(self):\n",
    "        print('name:', self.name)\n",
    "        print('age:',self.age, 'weight:',self.weight)\n",
    "a1=Admin(88,name='abc',age=11)\n",
    "\n",
    "AA= User(name ='lzl',age =18)\n",
    "print(AA.age)\n",
    "AA.show()\n",
    "BB= User()\n",
    "BB.show()\n",
    "\n",
    "print(BB.info)\n",
    "\n",
    "\n",
    "a1=Admin(88,name='abc',age=11)\n",
    "a2=Admin('abc2',11)\n",
    "a3=Admin(weight=58)\n",
    "\n",
    "print(a1.sex)\n",
    "a1.show()\n",
    "a2.show()\n",
    "a3.show()\n",
    "a3.info =89\n",
    "print(a3.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(config_list):\n",
    "    parser = argparse.ArgumentParser('argument for training')\n",
    "\n",
    "    parser.add_argument('--batch-size', type=int, default=512,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--num-workers', type=int, default=10,\n",
    "                        help='num of workers to use')\n",
    "\n",
    "    parser.add_argument('--training_type', type=str, default=\"Normal\",\n",
    "                        help='Normal, LabelSmoothing, AdvReg, DP, MixupMMD, PATE')\n",
    "    parser.add_argument('--mode', type=str, default=\"shadow\",\n",
    "                        help='target, shadow')\n",
    "\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of training epochs')\n",
    "    parser.add_argument('--gpu', type=int, default=0,\n",
    "                        help='gpu index used for training')\n",
    "\n",
    "    # model dataset\n",
    "    parser.add_argument('--model', type=str, default='resnet18')\n",
    "    parser.add_argument('--load-pretrained', type=str, default='no')\n",
    "    parser.add_argument('--task', type=str, default='mia',\n",
    "                        help='specify the attack task, mia or ol')\n",
    "    parser.add_argument('--dataset', type=str, default='CIFAR10',\n",
    "                        help='dataset')\n",
    "    parser.add_argument('--num-class', type=int, default=10,\n",
    "                        help='number of classes')\n",
    "    parser.add_argument('--inference-dataset', type=str, default='CIFAR10',\n",
    "                        help='if yes, load pretrained the attack model to inference')\n",
    "    parser.add_argument('--data-path', type=str, default='../datasets/',\n",
    "                        help='data_path')\n",
    "    parser.add_argument('--input-shape', type=str, default=\"32,32,3\",\n",
    "                        help='comma delimited input shape input')\n",
    "    parser.add_argument('--log_path', type=str,\n",
    "                        default='./save', help='data_path')\n",
    "    # 默认储存到save里 \n",
    "    \n",
    "\n",
    "    args = parser.parse_args(args= config_list)\n",
    "\n",
    "    args.input_shape = [int(item) for item in args.input_shape.split(',')]\n",
    "    args.device = 'cuda:%d' % args.gpu if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "0\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='test')\n",
    "\n",
    "parser.add_argument('--sparse', action='store_true', default=False, help='GAT with sparse version or not.')\n",
    "parser.add_argument('--seed', type=int, default=72, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=10000, help='Number of epochs to train.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=['--seed', '0',  '--sparse'])\n",
    "print(args.sparse)\n",
    "\n",
    "args = parser.parse_args(args=['--seed', '0'])\n",
    "\n",
    "print(args.sparse)\n",
    "print(args.seed)\n",
    "print(args.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = parse_args(['--mode', 'target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add simple data augmentation!\n",
      "add simple data augmentation!\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Preparing dataloader!\n",
      "dataset:  60000\n",
      "target_train: 10000 \t target_inference: 10000 \t target_test: 10000\n"
     ]
    }
   ],
   "source": [
    "s = GetDataLoader(opt)\n",
    "target_train_loader, target_inference_loader, target_test_loader, shadow_train_loader, shadow_inference_loader, shadow_test_loader = s.get_data_supervised()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_features, train_labels= next(iter(target_train_loader))\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img.T)\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from data_preprocessing import configs\n",
    "type(configs.SUPPORTED_IMAGE_DATASETS_ATTRIBUTE_INFERENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.mode == \"target\":\n",
    "        train_loader, inference_loader, test_loader = target_train_loader, target_inference_loader, target_test_loader\n",
    "        \n",
    "        # train_loader is a dataloader, using next(), feature shape is [128,3,32,32], label shape [128]\n",
    "    # \n",
    "elif opt.mode == \"shadow\":\n",
    "    train_loader, inference_loader, test_loader = shadow_train_loader, shadow_inference_loader, shadow_test_loader\n",
    "else:\n",
    "    raise ValueError(\"opt.mode should be target or shadow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_model(name=\"resnet18\", num_classes=10):\n",
    "    if name == \"resnet18\":\n",
    "        model = torchvision.models.resnet18()\n",
    "        model.fc = nn.Sequential(nn.Linear(512, 10))\n",
    "        # 代码修改了ResNet-18模型的最后一层全连接层，将其替换为一个新的全连接层nn.Linear(512, 10)，\n",
    "        # 其中512是ResNet-18模型中最后一个卷积层的输出通道数，10是类别数量。这样做是为了将模型的输出调整为与任务中的类别数量相匹配。\n",
    "    else:\n",
    "        raise ValueError(\"Model not implemented yet :P\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate(args, model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(args.device), labels.to(args.device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    model.train()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = get_target_model(name=\"resnet18\", num_classes=10)\n",
    "\n",
    "save_pth = f'{opt.log_path}2/{opt.dataset}/{opt.training_type}/{opt.mode}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./save2/CIFAR10/Normal/target'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{opt.log_path}2/{opt.dataset}/{opt.training_type}/{opt.mode}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[166], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m target_model(img)\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/data/anaconda3/envs/ml-hospital/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "img = train_features\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "img = img.to(device)\n",
    "target_model(img).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Total Sample: 10000, Train Acc: 31.910, Test Acc: 30.960, Total Time: 8.010s\n",
      "Train Epoch: 2, Total Sample: 10000, Train Acc: 37.250, Test Acc: 35.890, Total Time: 13.756s\n",
      "Train Epoch: 3, Total Sample: 10000, Train Acc: 41.660, Test Acc: 39.960, Total Time: 19.496s\n",
      "Train Epoch: 4, Total Sample: 10000, Train Acc: 45.250, Test Acc: 42.600, Total Time: 25.178s\n",
      "Train Epoch: 5, Total Sample: 10000, Train Acc: 35.050, Test Acc: 33.450, Total Time: 30.889s\n",
      "Train Epoch: 6, Total Sample: 10000, Train Acc: 47.960, Test Acc: 44.400, Total Time: 36.579s\n",
      "Train Epoch: 7, Total Sample: 10000, Train Acc: 49.860, Test Acc: 46.930, Total Time: 42.296s\n",
      "Train Epoch: 8, Total Sample: 10000, Train Acc: 36.120, Test Acc: 34.400, Total Time: 48.008s\n",
      "Train Epoch: 9, Total Sample: 10000, Train Acc: 56.720, Test Acc: 51.240, Total Time: 53.736s\n",
      "Train Epoch: 10, Total Sample: 10000, Train Acc: 49.010, Test Acc: 45.790, Total Time: 59.501s\n",
      "Train Epoch: 11, Total Sample: 10000, Train Acc: 49.430, Test Acc: 45.940, Total Time: 65.225s\n",
      "Train Epoch: 12, Total Sample: 10000, Train Acc: 59.080, Test Acc: 54.170, Total Time: 70.913s\n",
      "Train Epoch: 13, Total Sample: 10000, Train Acc: 55.840, Test Acc: 51.270, Total Time: 76.654s\n",
      "Train Epoch: 14, Total Sample: 10000, Train Acc: 55.980, Test Acc: 50.780, Total Time: 82.420s\n",
      "Train Epoch: 15, Total Sample: 10000, Train Acc: 61.710, Test Acc: 55.030, Total Time: 88.157s\n",
      "Train Epoch: 16, Total Sample: 10000, Train Acc: 62.260, Test Acc: 55.790, Total Time: 93.918s\n",
      "Train Epoch: 17, Total Sample: 10000, Train Acc: 66.010, Test Acc: 57.940, Total Time: 99.649s\n",
      "Train Epoch: 18, Total Sample: 10000, Train Acc: 59.120, Test Acc: 53.180, Total Time: 105.386s\n",
      "Train Epoch: 19, Total Sample: 10000, Train Acc: 61.320, Test Acc: 53.490, Total Time: 111.080s\n",
      "Train Epoch: 20, Total Sample: 10000, Train Acc: 66.670, Test Acc: 57.800, Total Time: 116.850s\n",
      "Train Epoch: 21, Total Sample: 10000, Train Acc: 67.370, Test Acc: 58.190, Total Time: 122.576s\n",
      "Train Epoch: 22, Total Sample: 10000, Train Acc: 60.410, Test Acc: 52.930, Total Time: 128.275s\n",
      "Train Epoch: 23, Total Sample: 10000, Train Acc: 65.600, Test Acc: 57.130, Total Time: 133.960s\n",
      "Train Epoch: 24, Total Sample: 10000, Train Acc: 70.340, Test Acc: 60.040, Total Time: 139.662s\n",
      "Train Epoch: 25, Total Sample: 10000, Train Acc: 70.390, Test Acc: 59.550, Total Time: 145.357s\n",
      "Train Epoch: 26, Total Sample: 10000, Train Acc: 71.940, Test Acc: 60.630, Total Time: 151.067s\n",
      "Train Epoch: 27, Total Sample: 10000, Train Acc: 68.740, Test Acc: 58.530, Total Time: 156.780s\n",
      "Train Epoch: 28, Total Sample: 10000, Train Acc: 69.940, Test Acc: 58.930, Total Time: 162.481s\n",
      "Train Epoch: 29, Total Sample: 10000, Train Acc: 66.500, Test Acc: 56.240, Total Time: 168.180s\n",
      "Train Epoch: 30, Total Sample: 10000, Train Acc: 70.920, Test Acc: 58.950, Total Time: 173.901s\n",
      "Train Epoch: 31, Total Sample: 10000, Train Acc: 76.430, Test Acc: 61.970, Total Time: 179.626s\n",
      "Train Epoch: 32, Total Sample: 10000, Train Acc: 72.240, Test Acc: 58.270, Total Time: 185.337s\n",
      "Train Epoch: 33, Total Sample: 10000, Train Acc: 75.840, Test Acc: 61.450, Total Time: 191.030s\n",
      "Train Epoch: 34, Total Sample: 10000, Train Acc: 63.340, Test Acc: 53.520, Total Time: 196.758s\n",
      "Train Epoch: 35, Total Sample: 10000, Train Acc: 80.740, Test Acc: 63.910, Total Time: 202.450s\n",
      "Train Epoch: 36, Total Sample: 10000, Train Acc: 80.560, Test Acc: 63.290, Total Time: 208.145s\n",
      "Train Epoch: 37, Total Sample: 10000, Train Acc: 72.150, Test Acc: 58.020, Total Time: 213.863s\n",
      "Train Epoch: 38, Total Sample: 10000, Train Acc: 72.290, Test Acc: 58.190, Total Time: 219.549s\n",
      "Train Epoch: 39, Total Sample: 10000, Train Acc: 77.520, Test Acc: 60.550, Total Time: 225.272s\n",
      "Train Epoch: 40, Total Sample: 10000, Train Acc: 80.160, Test Acc: 62.480, Total Time: 230.988s\n",
      "Train Epoch: 41, Total Sample: 10000, Train Acc: 79.680, Test Acc: 61.790, Total Time: 236.703s\n",
      "Train Epoch: 42, Total Sample: 10000, Train Acc: 80.940, Test Acc: 62.780, Total Time: 242.415s\n",
      "Train Epoch: 43, Total Sample: 10000, Train Acc: 83.080, Test Acc: 62.790, Total Time: 248.142s\n",
      "Train Epoch: 44, Total Sample: 10000, Train Acc: 79.860, Test Acc: 61.420, Total Time: 253.841s\n",
      "Train Epoch: 45, Total Sample: 10000, Train Acc: 82.370, Test Acc: 62.030, Total Time: 259.530s\n",
      "Train Epoch: 46, Total Sample: 10000, Train Acc: 78.400, Test Acc: 60.520, Total Time: 265.214s\n",
      "Train Epoch: 47, Total Sample: 10000, Train Acc: 83.740, Test Acc: 61.950, Total Time: 270.917s\n",
      "Train Epoch: 48, Total Sample: 10000, Train Acc: 88.910, Test Acc: 65.360, Total Time: 276.660s\n",
      "Train Epoch: 49, Total Sample: 10000, Train Acc: 80.860, Test Acc: 60.390, Total Time: 282.358s\n",
      "Train Epoch: 50, Total Sample: 10000, Train Acc: 85.260, Test Acc: 63.120, Total Time: 288.076s\n",
      "Train Epoch: 51, Total Sample: 10000, Train Acc: 89.380, Test Acc: 65.340, Total Time: 293.762s\n",
      "Train Epoch: 52, Total Sample: 10000, Train Acc: 89.210, Test Acc: 64.970, Total Time: 299.456s\n",
      "Train Epoch: 53, Total Sample: 10000, Train Acc: 86.940, Test Acc: 63.680, Total Time: 305.160s\n",
      "Train Epoch: 54, Total Sample: 10000, Train Acc: 90.160, Test Acc: 65.200, Total Time: 310.847s\n",
      "Train Epoch: 55, Total Sample: 10000, Train Acc: 86.280, Test Acc: 62.980, Total Time: 316.787s\n",
      "Train Epoch: 56, Total Sample: 10000, Train Acc: 90.410, Test Acc: 64.920, Total Time: 322.753s\n",
      "Train Epoch: 57, Total Sample: 10000, Train Acc: 90.390, Test Acc: 64.880, Total Time: 328.697s\n",
      "Train Epoch: 58, Total Sample: 10000, Train Acc: 90.940, Test Acc: 64.890, Total Time: 334.548s\n",
      "Train Epoch: 59, Total Sample: 10000, Train Acc: 92.950, Test Acc: 65.980, Total Time: 340.495s\n",
      "Train Epoch: 60, Total Sample: 10000, Train Acc: 92.190, Test Acc: 65.210, Total Time: 346.413s\n",
      "Train Epoch: 61, Total Sample: 10000, Train Acc: 93.750, Test Acc: 66.340, Total Time: 352.340s\n",
      "Train Epoch: 62, Total Sample: 10000, Train Acc: 90.390, Test Acc: 64.470, Total Time: 358.142s\n",
      "Train Epoch: 63, Total Sample: 10000, Train Acc: 93.940, Test Acc: 66.010, Total Time: 363.960s\n",
      "Train Epoch: 64, Total Sample: 10000, Train Acc: 94.830, Test Acc: 65.980, Total Time: 369.846s\n",
      "Train Epoch: 65, Total Sample: 10000, Train Acc: 94.660, Test Acc: 65.790, Total Time: 375.732s\n",
      "Train Epoch: 66, Total Sample: 10000, Train Acc: 95.400, Test Acc: 67.000, Total Time: 381.650s\n",
      "Train Epoch: 67, Total Sample: 10000, Train Acc: 94.020, Test Acc: 66.200, Total Time: 387.590s\n",
      "Train Epoch: 68, Total Sample: 10000, Train Acc: 92.130, Test Acc: 64.400, Total Time: 393.512s\n",
      "Train Epoch: 69, Total Sample: 10000, Train Acc: 96.090, Test Acc: 67.100, Total Time: 399.428s\n",
      "Train Epoch: 70, Total Sample: 10000, Train Acc: 95.940, Test Acc: 66.490, Total Time: 405.387s\n",
      "Train Epoch: 71, Total Sample: 10000, Train Acc: 96.140, Test Acc: 66.380, Total Time: 411.215s\n",
      "Train Epoch: 72, Total Sample: 10000, Train Acc: 96.810, Test Acc: 67.030, Total Time: 417.128s\n",
      "Train Epoch: 73, Total Sample: 10000, Train Acc: 96.270, Test Acc: 66.280, Total Time: 422.845s\n",
      "Train Epoch: 74, Total Sample: 10000, Train Acc: 96.550, Test Acc: 66.350, Total Time: 428.542s\n",
      "Train Epoch: 75, Total Sample: 10000, Train Acc: 95.750, Test Acc: 65.490, Total Time: 434.220s\n",
      "Train Epoch: 76, Total Sample: 10000, Train Acc: 97.440, Test Acc: 66.540, Total Time: 439.907s\n",
      "Train Epoch: 77, Total Sample: 10000, Train Acc: 97.780, Test Acc: 67.190, Total Time: 445.592s\n",
      "Train Epoch: 78, Total Sample: 10000, Train Acc: 97.470, Test Acc: 66.480, Total Time: 451.323s\n",
      "Train Epoch: 79, Total Sample: 10000, Train Acc: 97.780, Test Acc: 67.160, Total Time: 457.031s\n",
      "Train Epoch: 80, Total Sample: 10000, Train Acc: 98.000, Test Acc: 67.460, Total Time: 462.755s\n",
      "Train Epoch: 81, Total Sample: 10000, Train Acc: 97.740, Test Acc: 67.460, Total Time: 468.523s\n",
      "Train Epoch: 82, Total Sample: 10000, Train Acc: 98.320, Test Acc: 67.430, Total Time: 474.248s\n",
      "Train Epoch: 83, Total Sample: 10000, Train Acc: 98.060, Test Acc: 66.790, Total Time: 479.922s\n",
      "Train Epoch: 84, Total Sample: 10000, Train Acc: 98.240, Test Acc: 67.360, Total Time: 485.636s\n",
      "Train Epoch: 85, Total Sample: 10000, Train Acc: 98.480, Test Acc: 67.800, Total Time: 491.421s\n",
      "Train Epoch: 86, Total Sample: 10000, Train Acc: 98.500, Test Acc: 67.520, Total Time: 497.161s\n",
      "Train Epoch: 87, Total Sample: 10000, Train Acc: 98.610, Test Acc: 67.570, Total Time: 502.909s\n",
      "Train Epoch: 88, Total Sample: 10000, Train Acc: 98.420, Test Acc: 68.290, Total Time: 508.642s\n",
      "Train Epoch: 89, Total Sample: 10000, Train Acc: 98.560, Test Acc: 67.420, Total Time: 514.417s\n",
      "Train Epoch: 90, Total Sample: 10000, Train Acc: 98.640, Test Acc: 67.170, Total Time: 520.169s\n",
      "Train Epoch: 91, Total Sample: 10000, Train Acc: 98.770, Test Acc: 67.560, Total Time: 525.911s\n",
      "Train Epoch: 92, Total Sample: 10000, Train Acc: 98.670, Test Acc: 67.440, Total Time: 531.636s\n",
      "Train Epoch: 93, Total Sample: 10000, Train Acc: 98.810, Test Acc: 68.030, Total Time: 537.391s\n",
      "Train Epoch: 94, Total Sample: 10000, Train Acc: 98.880, Test Acc: 67.700, Total Time: 543.088s\n",
      "Train Epoch: 95, Total Sample: 10000, Train Acc: 98.680, Test Acc: 67.490, Total Time: 548.809s\n",
      "Train Epoch: 96, Total Sample: 10000, Train Acc: 98.910, Test Acc: 68.140, Total Time: 554.577s\n",
      "Train Epoch: 97, Total Sample: 10000, Train Acc: 98.720, Test Acc: 66.860, Total Time: 560.319s\n",
      "Train Epoch: 98, Total Sample: 10000, Train Acc: 98.680, Test Acc: 67.280, Total Time: 566.077s\n",
      "Train Epoch: 99, Total Sample: 10000, Train Acc: 98.970, Test Acc: 66.920, Total Time: 571.794s\n",
      "Train Epoch: 100, Total Sample: 10000, Train Acc: 98.800, Test Acc: 67.420, Total Time: 577.535s\n"
     ]
    }
   ],
   "source": [
    "total_evaluator = TrainTargetNormal(\n",
    "            model=target_model, epochs=opt.epochs, log_path=save_pth)\n",
    "total_evaluator.train(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-hospital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
